---
title: "Machine learning i"
author: "Natalia Alonso, Beatriz Martín y Susana Albarrán"
date: "7/2/2020"

fig_caption: yes

output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: flatly
    code_folding: show
---

<!-- Nota: Enlace a Github: https://github.com/natalonso/Practica_Fundamentos.git -->


# Objetivo del estudio



# Descripción de los datos

Los datos con los que se van a trabajar han sido extraidos de Kaggle: https://www.kaggle.com/harlfoxem/housesalesprediction

A continuación se van a describir las variables:

 **1.- Id**: es un identificador para cada casa que se ha vendido.  

 **2.- Date**: fecha de venta de la casa.  

 **3.- Price**: precio de venta de la casa.  

 **4.- Bedrooms**: número de habitaciones que tiene la casa.  

 **5.- Bathrooms**: número de cuartos de baño. Es importante destacar que 0.5 cuenta como baño que tiene ducha y no bañera. Esto lo tratamos con más detalle en el apartado de análisis de datos.

 **6.- Sqft_living**: pies cuadrados habitables.  

 **7.- Sqft_lot**: pies cuadrados del terreno de la parcela.  

 **8.- Floors**: número de plantas. Hay que tener en cuenta que se contabiliza 0.5 plantas cuando una planta no tiene todo el espacio construido. Por ejemplo la buhardilla.  

 **9.- Waterfront**: vistas al agua. Es una variable Dummy que nos dice si las casas tienen o no vistas al agua. 

 **10.- View**: vistas de la casa. Es una variable que toma valores de 0 a 4.

 **11.- Condition**: condiciones de la casa. Toma valores de 1 a 5. 

 **12.- Grade**: grados de calidad en la construccion. Toma valores de 1 a 13.

 **13.- Sqft_above**: pies cuadrados por encima del suelo.  

 **14.- Sqft_basement**: pies cuadrados del sótano.

 **15.- Yr_built**: año de construcción.

 **16.- Yr_renovated**: año en el que la casa se ha realizado.

 **17.- Zipcode**: en qué área se encuentra la casa. 

 **18.- Lat**: latitud.

 **19.- Long**: longitud.

 **20.- Sqft_living15**: pies cuadrados del interior de las 15 casas más cercanas.

 **21.- Sqft_lot15**: pies cuadrados del terreno de las 15 casas más cercanas.


```{r, lectura_datos, include=FALSE}

#datos <- read.csv("C:/Users/natal/OneDrive/Documentos/0_MIS_DOCUMENTOS/2.MÁSTER/2_Curso_2019-2020/Primer_Cuatrimestre/2.Fundamentos_de_Análisis/BloqueIV_Métodos/Práctica final/git/kc_house_data.csv")

datos <- read.csv("C:/Users/Beatriz/Desktop/Máster/1er trimestre/Fundamentos/Parte 4_Métodos de Análisis de datos/Prac_git/kc_house_data.csv")


#datos <- read.csv("C:/Users/susi_/Desktop/R/Practica_Fundamentos_R/Repositorios git/kc_house_data.csv")
```

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lattice)
library(dplyr)
library(VIM)
library(mice)
library(DMwR2)
library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)
library(GGally)
library(ggplot2)
library(corrplot)
library(vcd)
library(DT)
library(gridExtra)
library(jpeg)
library(car)
library(leaflet)
library(scales)
library(cowplot)
```

# Train, test y validación

Lo primero que se va a realizar es separar los datos en los 3 conjuntos de datos fundamentales:  

-  Conjunto de datos de **entrenamiento**: en nuestro estudio **datos_train**, se corresponde con el 70% del total de los datos.
-  Conjunto de datos de **validación**: en nuestro estudio **datos_validacion**, se corresponde con el 15% del total de los datos.
-  Conjunto de datos de **test**: en nuestro estudio **datos_test**, se corresponde con el 15% del total de los datos.

```{r, fig.align='center', warning=FALSE}

num_total=nrow(datos)
set.seed(122556) #reproductividad

# 70% para train
indices_train = sample(1:num_total, .7*num_total)
datos_train = datos[indices_train,]

# 15% para test
indices=seq(1:num_total)
indices_test=indices[-indices_train]
indices_test1 = sample(indices_test, .15*num_total)
datos_test = datos[indices_test1,]

# 15% para validacion
indices_validacion=indices[c(-indices_train,-indices_test1)]
datos_validacion=datos[indices_validacion,]

```


# Análisis exploratorio de datos

Para el análisis de los datos, se han dividido las variables en tres categorías:

  -**Variables de características de las casas**: price, bedrooms, bathrooms, floors, sqft_living, sqft_lot, sqft_above, sqfr_basement, sqft_living15 y sqft_lot15.
  
  -**Variables de calidad**: waterfront, view, condition, grade, yr_built y yr_renovated.
  
  -**Variables de localización**: zipcode, lat y long.

Visualizamos una muestra de los datos:

```{r, fig.align='center', warning=FALSE}
datatable(head(datos_train))   
```

Se muestra un resumen de los datos con los que se va a trabajar:

```{r, fig.align='center', warning=FALSE}
str(datos_train)
summary(datos_train)
```

Como la variable date no la vamos a utilizar porque es una serie temporal, la vamos a eliminar.

```{r, fig.align='center', warning=FALSE}
datos_train <- datos_train[,-2]
```

Antes de empezar con el análisis de cada variable, vamos a convertir a factor la variable id.

```{r, fig.align='center', warning=FALSE}
datos_train$id <- as.factor(datos_train$id)
```

## Características de las casas

A continuación, se va a realizar un análisis exploratorio para ver cómo se comporta cada variable:  

**-Variable price**: es numérica, es la variable respuesta del estudio:

```{r, fig.align='center', warning=FALSE}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x= price)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

```

Se observa que el precio de las casas es asimétrico, tiene mayor frecuencia hacia el lado izquierdo de la distribución. En estos casos se suele hacer una **transformación logarítmica**.

```{r, fig.align='center', warning=FALSE}

datos_train$log_price<- log10(datos_train$price)

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=log_price)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

```
 
Como se observa con la transformación logarítmica de la variable price (log_price), obtenemos una distribución más simétrica. 

**-Variable bedroom**: es numérica.

```{r, fig.align='center', warning=FALSE}
table(datos_train$bedrooms)
class(datos_train$bedrooms) 
```

```{r, fig.align='center', warning=FALSE}
p1<-ggplot(datos_train, aes(x=bedrooms)) + geom_histogram(colour="black", bins =30,fill="tomato")

p2<-ggplot(datos_train, aes(x=as.factor(bedrooms), y=log_price, fill=as.factor(bedrooms))) + geom_boxplot()+
labs(x="bedrooms")+theme(legend.position="none")

grid.arrange(p1, p2, nrow = 1)
```

Al generar la tabla y los gráficos se observa que hay casas con **0** habitaciones y **33** , más adelante tendremos que ver qué ocurre con estos datos.

Viendo el último gráfico podemos decir que según aumenta el número de habitaciones aumenta el precio de las casas.

 
**-Variable bathrooms**: es numérica.

```{r, fig.align='center', warning=FALSE}
table(datos_train$bathrooms)
```

La variable Bathrooms puede tomar valores decimales de 0.25 en 0.25. El número de baños se contabiliza por las piezas y cada baño completo tiene 4 piezas. 

-Baño (4 piezas) -> Inodoro, lavabo, bañera y ducha.(1 unidad) - Baño completo

-Baño (3 piezas) -> Inodoro, lavabo y ducha. (0.75 unidad) - Baño con ducha  

-Baño (2 piezas) -> Inodoro y lavabo. (0.5 unidad) - Aseo

-Baño (1 pieza) -> Inodoro (0.25 unidad) - Aseo

Vamos a agrupar los baños del siguiente modo:

-Valores: 0.25, 0.5, 0.75, 1 = 1 baño.

-Valores: 1.25, 1.5, 1.75, 2 = 2 baños.

Y así hasta 8 baños, que es el número máximo. Esto lo hacemos porque queremos agrupar los baños en función del número de estancias que ocupa, no en función del número de piezas que tenga.

```{r, fig.align='center', warning=FALSE}
datos_train$bathrooms_group <- cut(datos_train$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_train$bathrooms_group <- as.numeric(as.character(datos_train$bathrooms_group))

table(datos_train$bathrooms_group)

```

Se observa que hay 7 casas con cero baños, puede que estos datos se tengan que tratar más adelante.

````{r, fig.align='center', warning=FALSE}
#Dibujamos cómo queda agrupada enfrentada con la variable "price" ya transformada:
ggplot(datos_train, aes(x=as.factor(datos_train$bathrooms_group), y=log_price, fill=as.factor(datos_train$bathrooms_group))) + geom_boxplot()+
labs(x="bathrooms_group")+theme(legend.position="none")

```

Se puede observar cómo crece el precio de las casas a medida que aumenta el número de baños por casa.

**-Variable sqft_living**: es numérica. Se va a pintar un histograma y la densidad para ver su comportamiento. 

```{r, fig.align='center', warning=FALSE}

p5<-ggplot(datos_train, aes(x=sqft_living)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

p6<-ggplot(datos_train, aes(sqft_living, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "red") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 

grid.arrange(p5,p6, nrow=1)
```

En este segundo gráfico podemos ver que hay una relación creciente, a medida que aumentan los pies cuadrados aumenta el precio de las casas.

Viendo la distribución de la variable (primer gráfico), se va a realizar una transformación logarítmica:

```{r, fig.align='center', warning=FALSE}
datos_train$log_sqft_living<- log10(datos_train$sqft_living)

p5.1 <- ggplot(datos_train, aes(x=log_sqft_living)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

p6.1 <- ggplot(datos_train, aes(log_sqft_living, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "red") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000))

grid.arrange(p5.1,p6.1, nrow=1)
```

Se puede observar cómo ahora los datos se han normalizado.

**- Variable sqft_lot**: es una variable numérica, vamos a estudiar cómo se comporta.

```{r, fig.align='center', warning=FALSE}

p7<-ggplot(datos_train, aes(x=sqft_lot)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="tomato") 

p8<-ggplot(datos_train, aes(sqft_lot, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "blue") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 

grid.arrange(p7,p8, nrow=1)

```

Esta variable no parece que tenga una relación lineal muy clara con price, por lo que no vemos necesario hacer ninguna transformación ya que no la usaremos para la implementación del modelo.

**- Variable floors**: hay que tener en cuenta que se contabiliza 0.5 plantas cuando una planta no tiene todo el espacio construido. Por ejemplo, si la planta baja tiene $50m^2$, y la buhardilla tiene $20m^2$, floors va a tomar el valor de 1.5. Esta variable es numérica.

```{r, fig.align='center', warning=FALSE}
table(datos_train$floors)
``` 

Las casas tienen entre 1 planta y 3.5 plantas, aunque la mayoría de ellas tienen entre 1 y 2 plantas.

```{r, fig.align='center', warning=FALSE}
p9<-ggplot(datos_train, aes(x=as.factor(floors))) + geom_histogram(colour="black", stat ="count",fill="tomato")

p10<-ggplot(datos_train, aes(x=as.factor(floors), y=log_price, fill=as.factor(floors))) + geom_boxplot()+
labs(x="floors")+theme(legend.position="none")

grid.arrange(p9,p10, nrow=1)
```

Podemos observar cómo aparentemente el número de plantas no influye en el precio de las casas.

**- Variable sqft_above **: es numérica. Esta variable es la diferencia entre sqft_living y sqft_basement.

```{r, fig.align='center', warning=FALSE}

p16<-ggplot(datos_train, aes(x=sqft_above)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

p17<-ggplot(datos_train, aes(sqft_above, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "blue") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 

grid.arrange(p16,p17, nrow=1)
```

**- Variable sqft_basement **: es numérica, pero la vamos a hacer categórica.  

```{r, fig.align='center', warning=FALSE}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=sqft_basement)) + geom_histogram(bins=30, colour="black", fill="#E1AF00") 

```

Se observa que alrededor de unas 12.500 casas no tienen sótano, por lo que la vamos a transformar del siguiente modo:

- 0 -> casas que no tienen sótano.

- 1 -> casas que sí tienen sótano.

```{r, fig.align='center', warning=FALSE}
datos_train$sqft_basement_cat <- cut(datos_train$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))
table(datos_train$sqft_basement_cat)
```

Hay un 60% de casas que no tienen sótano y un 40% que sí lo tienen.

``` {r}
ggplot(datos_train, aes(x=log_price, fill= as.factor(sqft_basement_cat))) + geom_density(alpha=.3)

```

Se puede obervar que ambas categorías prácticamente siguen la misma distribución pero las casas que tienen sótano pueden llegar a ser más caras.

**- Variable sqft_living15 **: es numérica.

```{r, fig.align='center', warning=FALSE}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=sqft_living15)) + geom_histogram(bins=30, colour="black", fill="#E1AF00") 

```

La variable sqft_living15 está altamente correlacionada con sqft_living (como se verá en el apartado 5), por tanto no podremos considerar ambas para la creación del modelo. Además, ambas dan una información muy parecida, por este motivo, hemos decidido dar mayor importancia a sqft_living y con sqft_living15 no realizaremos ninguna transformación.

**- Variable sqft_lot15**: es numérica.

```{r, fig.align='center', warning=FALSE}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=sqft_lot15)) + geom_histogram(bins=30, colour="black", fill="#E1AF00") 

```

Entre sqft_lot y sqft_lot15 sucede lo mismo que con sqft_living y sqft_living15, ambas variables aportan la misma información y están muy correlacionadas entre sí, a partir de ahora tabajaremos con sqft_lot.

## Calidad

**- Variable waterfront**: es categórica. Toma valores 0 y 1 (dummy).  

 - 0 -> no tiene vistas al agua (se ha confirmado este dato con la latitud y longitud de la casa en google maps).
 - 1 -> tiene vistas al agua.

```{r, fig.align='center', warning=FALSE}
datos_train$waterfront<-as.factor(datos_train$waterfront)
table(datos_train$waterfront)
```

La mayoría de las casas no tiene vistas al agua.

```{r, fig.align='center', warning=FALSE}
ggplot(datos_train, aes(x=log_price, fill=as.factor(waterfront))) + geom_histogram(binwidth=0.1, alpha=.5, position="identity")

```

Se observa que las casas que tienen vistas al agua son más caras respecto de las que no tienen vistas al agua.
 
**- Variable view**: es categórica.Toma valores del 0 al 4. 

```{r, fig.align='center', warning=FALSE}

datos_train$view<-as.factor(datos_train$view)
table(datos_train$view)
```

El 90% de las casas toman el valor "0", es decir, sus vistas son normales.

```{r, fig.align='center', warning=FALSE}
p11<-ggplot(datos_train, aes(x=view)) + geom_histogram(colour="black",fill="tomato",stat="count")

p12<-ggplot(datos_train, aes(x=view, y=log_price, fill=as.factor(view))) + geom_boxplot()+
labs(x="view")+theme(legend.position="none")

grid.arrange(p11,p12, nrow=1)
```

Se observa que la mayoría de las casas no tienen buenas vistas y que las casas que tienen mejores vistas son más caras respecto de las otras.

**- Variable condition**: es categórica. Toma valores del 1 al 5.

```{r, fig.align='center', warning=FALSE}
datos_train$condition<-as.factor(datos_train$condition)
table(datos_train$condition)
```

La mayoría de casas tienen condición 3 y 4.

```{r, fig.align='center', warning=FALSE}
p13<-ggplot(datos_train, aes(x=condition)) + geom_histogram(colour="black", stat ="count",fill="tomato")

p14<-ggplot(datos_train, aes(x=as.factor(condition), y=log_price, fill=as.factor(condition))) + geom_boxplot()+
labs(x="condition")+theme(legend.position="none")

grid.arrange(p13,p14, nrow=1)
```

Podemos observar cómo la distribución para los distintos valores que toma la variable es constante respecto al precio. 

**- Variable grade**: es categórica. Toma valores del 1 al 13.

```{r, fig.align='center', warning=FALSE}
table(datos_train$grade)
```

```{r, fig.align='center', warning=FALSE}
p14<-ggplot(datos_train, aes(x=as.factor(grade))) + geom_histogram(colour="black", stat ="count",fill="tomato")

p15<-ggplot(datos_train, aes(x=as.factor(grade), y=log_price, fill=as.factor(grade))) + geom_boxplot()+
labs(x="grade")+theme(legend.position="none")

grid.arrange(p14,p15, nrow=1)
```

Cuando se enfrenta con la variable precio se ve que a mayor grado es mayor el precio de las casas.

Se va a volver a categorizar del siguiente modo:

 - Valores de 1-4 -> calidad baja, se va a categorizar con valor 0
 - Valores de 5-9 -> calidad media, se va a categorizar con valor 1
 - Valores de 10-13 -> calidad alta, se va a categorizar con valor 2
 
```{r, fig.align='center', warning=FALSE}
datos_train$grade_categ <- cut(datos_train$grade, breaks = c(0,4,9,13), labels = c(0,1,2))
table(datos_train$grade_categ)
```

```{r, fig.align='center', warning=FALSE}
#Dibujamos cómo queda categorizada enfrentada con la variable "log_price"
ggplot(datos_train, aes(x=as.factor(datos_train$grade_categ), y=log_price, fill=as.factor(datos_train$grade_categ))) + geom_boxplot() + labs(x="grade_categ")+theme(legend.position="none")
```

Sigue el mismo patrón que antes, es decir, a mayor grado mayor precio.

**- Variable yr_built  **: es numérica.

```{r, fig.align='center', warning=FALSE}
table(datos_train$yr_built)
```

Los años de construcción van desde el 1900 hasta el 2015.

```{r, fig.align='center', warning=FALSE}
options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=yr_built)) + geom_histogram(colour="black",bins=30, fill="#E1AF00") 
```

Se observa que a medida que iba pasando el tiempo, por regla general, se han ido construyendo más casas.

**- Variable yr_renovated  **: categórica.

```{r, fig.align='center', warning=FALSE}
table(datos_train$yr_renovated)

```

Se observa que hay un año "0" y entendemos que son casas que no han tenido ningún tipo de renovación. La vamos a categorizar como:
 
 - 0 -> no ha tenido renovación (valor 0)
 - 1 -> sí ha tenido renovación (resto de años)

```{r, fig.align='center', warning=FALSE}
datos_train$yr_renovated_catg <-cut(datos_train$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))
table(datos_train$yr_renovated_catg)

```

La mayoría de casas no han tenido ninguna renovación.

```{r, fig.align='center', warning=FALSE}
#Dibujamos cómo queda categorizada enfrentada con la variable "log_price"
ggplot(datos_train, aes(x=as.factor(datos_train$yr_renovated_catg), y=log_price, fill=as.factor(datos_train$yr_renovated_catg))) + geom_boxplot() + labs(x="0-No renovación / 1-Renovación")+theme(legend.position="none")

```

Se comportan de una manera similar respecto al precio.

## Localización

En este apartado vamos a analizar cómo se comportan las variables de localización respecto al precio.


**- Variable zipcode **: es categórica.  

```{r, fig.align='center', warning=FALSE}
datos_train$zipcode<-as.factor(datos_train$zipcode)
table(datos_train$zipcode)
```

Hay 70 códigos postales distintos, por lo que hay 70 zonas distintas en nuestro estudio.

**- Variables lat y long **: son numéricas. 

```{r, fig.align='center', warning=FALSE}
datos_train$Pricegroup<-cut(datos_train$price, c(0,250000,500000,750000,1000000,2000000,100000000), labels = c("Entre 0 y 250$","Entre 250$ y 500$","Entre 500$ y 750$","Entre 750$ y 1.000$","Entre 1.000$ y 2.000$","Más de 2.000$"))

center_lon = median(datos_train$long,na.rm = TRUE)
center_lat = median(datos_train$lat,na.rm = TRUE)

factpal <- colorFactor(c("black","blue","yellow","orange","pink","red"), 
                       datos_train$Pricegroup )

leaflet(datos_train) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal(Pricegroup))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal , values = ~Pricegroup,
            title = "Precio (en miles de $)",
            opacity = 1)

```


Como podemos ver en el mapa, las casas más caras son las que están cerca del lago. También se observa lo siguiente:
 
   -  En el caso de **zipcode** podríamos agruparlo por códigos postales, aunque si observamos la correlación con el precio no es indicativa, ya que tiene un valor negativo próximo a cero.
   -  **lat**, **long**, a lo mejor se podría agrupar por tres tipos de latitud y longitud distintas.
 

# Detección, tratamiento e imputación de datos faltantes

En nuestros datos no tenemos datos faltantes, pero gracias al análisis exploratorio previamente hecho nos hemos dado cuenta de que tenemos outliers en diferentes variables.

```{r, fig.align='center', warning=FALSE}
#Contar el total de NAs en la base de datos
sum(is.na(datos_train))

```

En el caso de la variable **Bedrooms** hemos visto que hay 7 casas con 0 habitaciones y una con 33. 

Como en nuestro estudio no tenemos datos faltantes, hemos comprobado con la latitud y la longitud (véase la Figura 1), que la casa con 33 habitaciones es un dato erróneo, ya que su estructura es muy parecida a las casas de los alrededores y no tienen 33 habitaciones. Lo que vamos a hacer a continuación es suponer que la casa con 33 habitaciones es un NA y estudiar cómo imputar ese dato faltante.

```{r, fig.align='center', warning=FALSE}
datos_train[datos_train$bedrooms==33,c(2:20)]
```

![](Casa con 33 habitaciones_v2.jpeg){width=90%}

<div style="text-align: center">
Figura 1. Casa con 33 habitaciones.
</div>


Primero nos vamos a crear un dataframe auxiliar para probar diferentes métodos y poder tomar una decisión.

```{r, fig.align='center', warning=FALSE}
datos_train$posicion<-c(1:nrow(datos_train))

indice_hab33 <- datos_train[datos_train$bedrooms==33,]$posicion
indice_hab33

datos_train_aux1 <- datos_train
datos_train_aux1$bedrooms[datos_train_aux1$bedrooms==33] <-NA

datos_train_aux2 <- datos_train
datos_train_aux2$bedrooms[datos_train_aux2$bedrooms==33] <-NA

datos_train_aux3 <- datos_train
datos_train_aux3$bedrooms[datos_train_aux3$bedrooms==33] <-NA
```

## Imputación con regresión lineal

A continuación vamos a realizar la imputación de dato faltante con regresión lineal:

```{r, fig.align='center', warning=FALSE}
#log_price,bedrooms,bathrooms_group,log_sqft_living,sqft_lot,floors,sqft_above,lat,long
datos_mice<-datos_train_aux1[,c(21,3,22,23,6,7,12,17,18)]

# Imputación con regresión lineal:
imp_1 = mice(datos_mice, method = "norm.predict", m=1) # Cálculo método de imputación
datostrain_mice = complete(imp_1)  # Imputación de valores
datostrain_mice$posicion<-c(1:nrow(datostrain_mice))

#Ha imputado:
datostrain_mice[datostrain_mice$posicion == indice_hab33,]$bedrooms

```

Ha imputado con el valor 3.118659. Como las habitaciones toman valores discretos, nos quedamos con 3 habitaciones.

## Imputación con regresión estocástica

```{r, fig.align='center', warning=FALSE}
datos_mice2<-datos_train_aux2[,c(21,3,22,23,6,7,12,17,18)]

# Imputación multiple, regresión estocástica:
imp_2 = mice(datos_mice2, method = "norm.nob", seed=1234)# Cálculo método de imputación
datostrain_mice2 = complete(imp_2)  # Imputación de valores sustiyuye 33
datostrain_mice2$posicion<-c(1:nrow(datostrain_mice2))

#Ha imputado:
datostrain_mice2[datostrain_mice2$posicion == indice_hab33,]$bedrooms

```

En este caso el valor que toma es 3.122092, por lo que coincide con el anterior en que son 3 habitaciones lo que tenemos que imputar.

## Imputación comparando los vecinos más cercanos

Otro modo de imputar el dato faltante es compararlo con los vecinos más cercanos. Para ello, lo que hemos hecho es calcular la diferencia entre la latitud de la casa con 33 habitaciones con el resto y lo mismo para la longitud. Luego hemos sumado esas diferencias y nos hemos quedado con las 15 distancias más pequeñas.

```{r, fig.align='center', warning=FALSE}
datos_train_aux3$diferencia_lat<- abs(datos_train$lat[datos_train$bedrooms==33]-datos_train[,17])
datos_train_aux3$diferencia_long<- abs(datos_train$long[datos_train$bedrooms==33]-datos_train[,18])
datos_train_aux3$diferencia_total <- datos_train_aux3$diferencia_lat+datos_train_aux3$diferencia_long

casas_mas_cercanas <- as.data.frame(sort(datos_train_aux3$diferencia_total,index.return=TRUE))
indices_casas_cercanas <- casas_mas_cercanas$ix[2:16] # la primera no se coge porque es la propia casa con 33 habitaciones

mean(datos_train_aux3$bedrooms[indices_casas_cercanas])
```

El resultado que obtenemos en este caso es 3.2. Al igual que en los métodos anteriores, la imputación sería de 3 habitaciones.

Por lo que finalmente imputamos que esa casa tiene 3 habitaciones.

```{r, fig.align='center', warning=FALSE}
datos_train[datos_train$posicion == indice_hab33,]$bedrooms = 3
```

## Eliminación de Outliers

Como hemos comentado anteriormente, teníamos 7 observaciones con 0 baños y otras 7 con 0 casas, se ha decidido eliminar estas filas de la base de datos, ya que respecto al número de observaciones totales de los datos de entrenamiento es muy poco representativo y no va a afectar al resultado.

```{r, fig.align='center', warning=FALSE}

indices_cero_habitaciones<-datos_train[datos_train$bedrooms==0,]$posicion
datos_train<-datos_train[-indices_cero_habitaciones,]

datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_banos<-datos_train$posicion[datos_train$bathrooms_group==0]
datos_train<-datos_train[-indices_cero_banos,]
```


# Selección de variables

Para hacer una selección de variables ya hemos estudiado como se comportan con la variable precio. A continuación se va a realizar una matriz de correlaciones para terminar de decidir con qué variables nos quedamos:

```{r, fig.align='center', warning=FALSE}

datos_train_cor2 <- datos_train[,c(21,3,22,23,6,7,12,17:20)]
correlation_matrix2 <- cor(datos_train_cor2, method = "spearman")
corrplot(correlation_matrix2, method = "color", tl.srt=45, addCoef.col ="black", number.cex =0.6,
         tl.cex = 0.7,tl.col="black", type= "upper")
```


# Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple

Antes de crear el modelo, vamos a crear un nuevo dataframe con las variables que vamos a usar y vamos a reescalarlas. Primero vamos a hacer una prueba para ver que tipo de reescalado es el más adecuado, para ello se representan 4 posibles versiones del reescalado sobre la variable respuesta log_price para ver el efecto de cada tipo de escalado.

```{r, fig.align='center', warning=FALSE}
# Creamos un nuevo dataframe limpio, con las variables ya transformadas y categorizadas
datos_train_model <- datos_train[c(1,21,3,22,23,6,7:10,25,12,24,17:20,26)]

# Re-escalado de variables:

#FORMA-0: sin reescalar
f1<-ggplot(datos_train_model, aes(x=log_price)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="Sin reescalar")

#FORMA-1: F-score scaling: resta la media y divide por la desviación tipica
f2<-ggplot(datos_train_model, aes(x=scale(datos_train_model$log_price, center = TRUE, scale = TRUE) )) + geom_density(alpha=.3, fill="#E1AF00") + labs(x="Reescalado F-score o estandarización")

#FORMA-2: 0-1 scaling: (V - min V)/(max V - min V)
f3<-ggplot(datos_train_model, aes(x=rescale(datos_train_model$log_price))) + geom_density(alpha=.3, fill="#E1AF00") + labs(x="Reescalado con normalización min-max")

#FORMA-3: Scaling to unit length based on the euclidean length
f4<-ggplot(datos_train_model, aes(x=datos_train_model$log_price/sqrt(sum(datos_train_model$bedrooms^2)))) + geom_density(alpha=.3, fill="#E1AF00") + labs(x="Reescalado por longitud euclidea")

grid.arrange(f1,f2,f3,f4, nrow=2)

```

Finalmente, decidimos que el más adecuado para nuestro análisis iba a ser la estandarización (ya que con este tipo de reescalado no nos afecta tanto la presencia de outliers como en la normalización, que depende tanto del valor máximo como mínimo).

```{r, fig.align='center', warning=FALSE}
# para variables numéricas: log_price, bedrooms, bathrooms_group, log_sqft_living, sqft_lot, floors, sqft_above, sqft_living_15, sqft_lot_15

f1<-ggplot(datos_train_model, aes(x=log_price)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="log_price")

f2<-ggplot(datos_train_model, aes(x=bedrooms)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="bedrooms")

f3<-ggplot(datos_train_model, aes(x=bathrooms_group)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="bathrooms_group")

f4<-ggplot(datos_train_model, aes(x=log_sqft_living)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="log_sqft_living")

f5<-ggplot(datos_train_model, aes(x=sqft_lot)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_lot")

f6<-ggplot(datos_train_model, aes(x=floors)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="floors")

f7<-ggplot(datos_train_model, aes(x=sqft_above)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_above")

f8<-ggplot(datos_train_model, aes(x=sqft_living15)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_living15")

f9<-ggplot(datos_train_model, aes(x=sqft_lot15)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_lot15")


grid.arrange(f1,f2,f3,f4,f5,f6,f7,f8,f9, nrow=3)

datos_train_model_reescalado <- datos_train_model

datos_train_model_reescalado$log_price=c(scale(datos_train_model$log_price))
datos_train_model_reescalado$bedrooms=c(scale(datos_train_model$bedrooms))
datos_train_model_reescalado$bathrooms_group=c(scale(datos_train_model$bathrooms_group))
datos_train_model_reescalado$log_sqft_living=c(scale(datos_train_model$log_sqft_living))
datos_train_model_reescalado$sqft_lot=c(scale(datos_train_model$sqft_lot))
datos_train_model_reescalado$floors=c(scale(datos_train_model$floors))
datos_train_model_reescalado$sqft_above=c(scale(datos_train_model$sqft_above))
datos_train_model_reescalado$sqft_living15=c(scale(datos_train_model$sqft_living15))
datos_train_model_reescalado$sqft_lot15=c(scale(datos_train_model$sqft_lot15))


f1<-ggplot(datos_train_model_reescalado, aes(x=log_price)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="log_price")

f2<-ggplot(datos_train_model_reescalado, aes(x=bedrooms)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="bedrooms")

f3<-ggplot(datos_train_model_reescalado, aes(x=bathrooms_group)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="bathrooms_group")

f4<-ggplot(datos_train_model_reescalado, aes(x=log_sqft_living)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="log_sqft_living")

f5<-ggplot(datos_train_model_reescalado, aes(x=sqft_lot)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_lot")

f6<-ggplot(datos_train_model_reescalado, aes(x=floors)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="floors")

f7<-ggplot(datos_train_model_reescalado, aes(x=sqft_above)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_above")

f8<-ggplot(datos_train_model_reescalado, aes(x=sqft_living15)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_living15")

f9<-ggplot(datos_train_model_reescalado, aes(x=sqft_lot15)) + geom_density(alpha=.3, fill="#E1AF00") +
  labs(x="sqft_lot15")


grid.arrange(f1,f2,f3,f4,f5,f6,f7,f8,f9, nrow=3)

```
        

## Creación del modelo manual

Para crear el modelo manual, hemos ido introduciendo variables para ver como se ajustaba el coeficiente de determinación.

Para este apartado nos hemos basado en la matriz de correlaciones del apartado anterior y en los gráficos del análisis exploratorio.

  -**Modelo1a**: hemos añadido las variables que mayor correlación tienen con nuestra variable respuesta, log_sqft_living (0.65), bathrooms_group (0.49) y lat (0.46) y las que con los gráficos se visualizaba que el precio aumentaba grade_categ.
  
  El **Modelo1a** es capaz de explicar casi el 67%  de la variabilidad observada en el precio de las casas (R-squared: 0.6699 ). El valor de $R^2$-ajustado es muy  cercano al $R^2$ (Adjusted R-squared: 0.6697) lo que indica que el modelo contiene predictores útiles.

```{r, fig.align='center', warning=FALSE}

modelo1a<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat, data = datos_train_model)
summary(modelo1a)

```
 
   -**Modelo1b**: hemos añadido las variables que mayor correlación tienen con nuestra variable respuesta, log_sqft_living (0.65), bathrooms_group (0.49) y lat (0.46) y las que con los gráficos se visualizaba que el precio aumentaba grade_categ y view.
  
   El **Modelo1b** es capaz de explicar casi el 70%  de la variabilidad observada en el precio de las casas (R-squared: 0.6982). El valor de $R^2$-ajustado es muy cercano al $R^2$ (Adjusted R-squared: 0.698) lo que indica que el modelo contiene predictores útiles. Sin embargo, este modelo al seleccionar la variable view, introduce 4 dummies, y por este motivo no escogeremos este modelo.
  
```{r, fig.align='center', warning=FALSE}

modelo1b<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + view, data = datos_train_model)
summary(modelo1b)

```

  -**Modelo2**: hemos añadido las variables que mayor correlación tienen con nuestra variable respuesta, log_sqft_living (0.65), bathrooms_group (0.49) y lat (0.46) y las que con los gráficos se visualizaba que el precio aumentaba grade_categ y waterfront.
  
   El **Modelo2** es capaz de explicar el 68%  de la variabilidad observada en el precio de las casas (R-squared: 0.6829 ). El valor de $R^2$-ajustado es muy  cercano al $R^2$ (Adjusted R-squared: 0.6828) lo que indica que el modelo contiene predictores útiles. El test F muestra un p-value de 0.22e-15 por lo que el modelo en conjunto es significativo. Esto se corrobora con el p-value de cada predictor, en ambos casos significativo excepto grade_categ1 (se podría volver a categorizar esta variable).
  
  Como el modelo 2, será el que finalmente elijamos, vamos a ver las diferencias entre reescalar las variables o no reescalarlas. 
  
  
```{r, fig.align='center', warning=FALSE}

modelo2<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + waterfront, data = datos_train_model)
summary(modelo2) #-----> ELEGIDO!!

modelo2_reescalado<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + waterfront, data = datos_train_model_reescalado)
summary(modelo2_reescalado)

```

Como se observa, vemos que los resultados se parecen mucho, de hecho sólo cambian los coeficientes, pero los p-valores de cada $Beta$ no varían. El $R^2$ y $R^2$ ajustado son los mismos. Más adelante haremos el estudio de inflación de la varianza (VIF) y decidiremos si nos quedamos con el reescalado. 


**Conclusión**: Hemos visto que con waterfront y view, bedrooms y bathrooms_group, y log_sqft_living y sqft_living15, respectivamente, teniendo el resto de variables iguales, afectan mínimamente al $R^2$-ajustado. Por otro lado, yr_renovated_catg y long no aportan al modelo.

Finalmente hemos seleccionado el **Modelo2**, ya que hemos ido haciendo pruebas con las distintas variables que pensabamos que podían aportar valor al modelo pero hemos observado que el cambio es mínimo (0.01).

Aunque el modelo1b tiene un $R^2$ mayor, estamos introduciendo más variables y como hemos comentado anteriormente apenas sube el coeficiente (0.01), por lo que elegimos el modelo más sencillo (principio de parsimonia).


### Estudio de colinealidad (VIF)

A continuación, vamos a usar el **Factor de Inflación de la Varianza (VIF)**, para ver si existe colinealidad entre las variables seleccionadas para el modelo. Los límites de referencia que se suelen emplear son:

 - VIF = 1: Ausencia total de colinealidad.
 - 1 < VIF < 5: La regresión puede verse afectada por cierta colinealidad.
 - 5  < VIF < 10: Causa de preocupación.
 

```{r, fig.align='center', warning=FALSE}
vif(modelo2)
vif(modelo2_reescalado)
```

En los dos modelos, con y sin reescalado, vemos que no hay índices altos de colinealidad por lo que la elección de las variables es buena. Además, no hay diferencia entre el modelo 2 con y sin reescalado de variables numéricas.

Por lo tanto, viendo este resultado junto al anterior decidimos quedarnos con el **modelo2 sin reeescalar**.

### Análisis de residuos

Se va a comprobar las hipótesis que deben de cumplirse para poder utilizar el modelo2. 

  - Normalidad de los residuos
  - Independencia de los residuos
  - Homocedasticidad (igualdad de las varianzas de los residuos)
  - Linealidad de los residuos

Se obtienen 4 gráficos que nos ayudan para la validación del modelo. Estos gráficos son:

  - Valores predichos frente a residuos
  - Gráfico Q-Q de normalidad
  - Valores predichos frente a raíz cuadrada de los residuos estandarizados (en valor absoluto)
  - Residuos estandarizados frente a leverages 

```{r, fig.align='center', warning=FALSE}
par(mfrow=c(2,2))
plot(modelo2)

```

Los gráficos 1 y 3 se utilizan para contrastar gráficamente la independencia, la homocedasticidad y la linealidad de los residuos. Idealmente, los residuos deben estar aleatoriamente distribuidos a lo largo del gráfico, sin formar ningún tipo de patrón.

El gráfico Q-Q, (Gráfico 2) por su parte, se utiliza para contrastar la normalidad de los residuos. Lo deseable es que los residuos estandarizados estén lo más cerca posible a la línea punteada que aparece en el gráfico. En este estudio se ve que en los extremos se desvian de la recta.

El gráfico de residuos estandarizados frente a leverage (Gráfico 4) se utiliza para detectar puntos con una influencia importante en el cálculo de las estimaciones de los parámetros. En caso de detectarse algún punto fuera de los límites que establecen las líneas discontinuas debe estudiarse este punto de forma aislada para detectar, por ejemplo, si la elevada importancia de esa observación se debe a un error.

No parece que los residuos sigan una distribución Normal. Vamos a confirmar si esto es así mediante métodos analíticos (Test de normalidad Kolmogorov-Smirnov)

#### Test Normalidad Kolmogorov-Smirnov

Partimos de la Hipótesis nula de que los residuos del modelo se distribuyen como una Normal.

```{r, fig.align='center', warning=FALSE}

ks.test(modelo2$residuals, 'pnorm')
```

Los resultados del test nos confirman lo que se intuía en el gráfico Q-Q: los residuos no siguen una distribución normal, puesto que el p-valor que se obtiene (0.22-e16) es menor que 0.1. Por lo que debemos rechazar la Hipótesis nula, es decir los residuos no se distribuyen como una distribución Normal.


## Creación del modelo por selección automática.

Para comprobar si nuestra elección del modelo es la correcta, vamos a usar técnicas de selección automática.

### Forward

Este método parte de un conjunto de variables vacío, de manera que este se incrementa con la variable que más mejora el modelo para la métrica seleccionada. Se incluye una variable a cada paso, hasta que se llega al número seleccionado o el modelo no mejora más.

```{r, fig.align='center', warning=FALSE}
#la función regsubsets con el método forward por defecto evalua 8 subconjuntos diferentes, en función del número de variables que quieras que tenga tu modelo, puedes hacer coef(modelo,n_variables_modelo)

mejor_modelo_forward <- leaps::regsubsets(log_price~., datos_train_model[,-1], method="forward") #forward
mejor_modelo_forward

reg_sum_forward <- summary(mejor_modelo_forward)
reg_sum_forward

reg_sum_forward$adjr2
coef(mejor_modelo_forward,5)

```

Como se observa, el $R^2$ Ajustado nos proporciona 0.6954, aumenta respecto al modelo 2 en 0.01. Pero al obtener las variables predictoras del modelo con sus coeficientes, incluye sqft_living15, la cual está altamente correlada con log_sqft_living (0.75) y nosotros la hemos descartado de nuestro modelo2.


### Backward

Se parte del conjunto de todas las variables, de manera que este se disminuye con la variable que más mejora el modelo para la métrica seleccionada. Se elimina una variable a cada paso, hasta que se llega al número seleccionado o el modelo no mejora más.

```{r, fig.align='center', warning=FALSE}
mejor_modelo_backward <- leaps::regsubsets(log_price~., datos_train_model[,-1], method="backward") #backward
mejor_modelo_backward

reg_sum_backward <- summary(mejor_modelo_backward)
reg_sum_backward

reg_sum_backward$adjr2
coef(mejor_modelo_backward,5)

```

Como se observa, el $R^2$ Ajustado nos proporciona 0.6954, aumenta respecto al modelo 2 en 0.01. Pero al obtener las variables predictoras del modelo con sus coeficientes, incluye sqft_living15, la cual está altamente correlada con log_sqft_living (0.75) y nosotros la hemos descartado de nuestro modelo2.

**Conclusión**: Se han usado las técnicas de selección automática para ver si podíamos aumentar el coeficiente de correlación significativamente, pero observamos que apenas sube (0.01) respecto al modelo que hemos construido manualmente (modelo2), por lo que finalmente elegimos el modelo2, ya que pensamos que es el modelo que permite predecir con mayor precisión el precio de las casas.


# Test

Una vez realizado el análisis exploratorio de datos e implementado el modelo, vamos a comprobar si con el modelo elegido, obtenemos una buena predicción del precio. Para ello, ahora usaremos los datos de test. Primero, realizaremos las mismas transformaciones, agrupaciones y categorizaciones que realizamos con los datos de train. A continuación, con la función *predict*, aplicaremos el modelo 2, finalmente seleccionado, a los nuevos datos, obteniendo así la predicción del precio.


```{r, fig.align='center', warning=FALSE}

#id
datos_test$id <- as.factor(datos_test$id)

#price
datos_test$log_price <- log10(datos_test$price)

#bathrooms
datos_test$bathrooms_group <- cut(datos_test$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_test$bathrooms_group <- as.numeric(datos_test$bathrooms_group)

#sqft_living
datos_test$log_sqft_living<- log10(datos_test$sqft_living)

#waterfront
datos_test$waterfront <- as.factor(datos_test$waterfront)

#view
datos_test$view <- as.factor(datos_test$view)

#condition
datos_test$condition <- as.factor(datos_test$condition)

#grade
datos_test$grade_categ <- cut(datos_test$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

#sqft_basement
datos_test$sqft_basement_cat <- cut(datos_test$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

#yr_renovated
datos_test$yr_renovated_catg <-cut(datos_test$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

#datos de test solo con las variables transformadas y sin la variable respuesta
datos_test_mod <- datos_test[c(1,22,4,23,24,7:11,25,13,26,15,27,17:21)]
```

```{r, fig.align='center', warning=FALSE}
#eliminamos la variable respuesta para predecir
predict_precio_test <- as.data.frame(predict(modelo2, newdata = datos_test_mod[-2,]))
colnames(predict_precio_test)[1] <- "predict_precio"

```

## Variable respuesta test vs valor predicho

Una vez obtenida la predicción del precio usando el modelo2, comparamos con el precio real calculando la diferencia entre ambos. Finalmente, hallamos la media de todas las diferencias y comprabamos que de media hay una diferencia de 133861.8$ aproximadamente. 

```{r, fig.align='center', warning=FALSE}
datos_test_mod$id_aux <- rownames(datos_test_mod)
predict_precio_test$id_aux <- rownames(predict_precio_test)

comparacion <- merge(datos_test_mod,predict_precio_test,by="id_aux")
comparacion <- comparacion[,c(1,3,22)]
```

```{r, fig.align='center', warning=FALSE}
comparacion$precio_diff <- abs(10^(comparacion$log_price) - 10^(comparacion$predict_precio)) #unidades naturales
dif_media_test_unidades_naturales<-mean(comparacion$precio_diff)
dif_media_test_unidades_naturales

comparacion$log_price_nat <- 10^(comparacion$log_price)
comparacion$predict_precio_nat <- 10^(comparacion$predict_precio)

comparacion$precio_diff2 <- abs(comparacion$log_price_nat-comparacion$predict_precio_nat)
dif_media_test_unidades_naturales2<-mean(comparacion$precio_diff2)
dif_media_test_unidades_naturales2
```



# Validación

Una vez obtenidos los resultados con los datos de test, realizamos una última comprobación repitiendo el mismo proceso con los datos de validación. Realizamos las transformaciones y obtenemos la predicción del precio usando el modelo 2.

```{r, fig.align='center', warning=FALSE}

#id
datos_validacion$id <- as.factor(datos_validacion$id)

#price
datos_validacion$log_price <- log10(datos_validacion$price)

#bathrooms
datos_validacion$bathrooms_group <- cut(datos_validacion$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_validacion$bathrooms_group <- as.numeric(datos_validacion$bathrooms_group)

#sqft_living
datos_validacion$log_sqft_living<- log10(datos_validacion$sqft_living)

#waterfront
datos_validacion$waterfront <- as.factor(datos_validacion$waterfront)

#view
datos_validacion$view <- as.factor(datos_validacion$view)

#condition
datos_validacion$condition <- as.factor(datos_validacion$condition)

#grade
datos_validacion$grade_categ <- cut(datos_validacion$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

#sqft_basement
datos_validacion$sqft_basement_cat <- cut(datos_validacion$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

#yr_renovated
datos_validacion$yr_renovated_catg <-cut(datos_validacion$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

#datos de validacion solo con las variables transformadas y sin la variable respuesta
datos_validacion_mod <- datos_validacion[c(1,22,4,23,24,7:11,25,13,26,15,27,17:21)]
```

```{r, fig.align='center', warning=FALSE}
#eliminamos la variable respuesta para predecir
predict_precio_validacion <- as.data.frame(predict(modelo2, newdata = datos_validacion_mod[-2,]))
colnames(predict_precio_validacion)[1] <- "precio_pred"
```

## Variable respuesta validación vs valor predicho

```{r, fig.align='center', warning=FALSE}
datos_validacion_mod$id_aux <- rownames(datos_validacion_mod)
predict_precio_validacion$id_aux <- rownames(predict_precio_validacion)

comparacion_val <- merge(datos_validacion_mod,predict_precio_validacion,by="id_aux")
comparacion_val <- comparacion_val[,c(1,3,22)]
```

```{r, fig.align='center', warning=FALSE}
comparacion_val$precio_diff <- abs(10^(comparacion_val$log_price) - 10^(comparacion_val$precio_pred)) #unidades naturales
dif_media_test_unidades_naturales<-mean(comparacion_val$precio_diff)
dif_media_test_unidades_naturales

comparacion_val$log_price_nat <- 10^(comparacion_val$log_price)
comparacion_val$predict_precio_nat <- 10^(comparacion_val$precio_pred)

comparacion_val$precio_diff2 <- abs(comparacion_val$log_price_nat-comparacion_val$predict_precio_nat)
dif_media_test_unidades_naturales2<-mean(comparacion_val$precio_diff2)
dif_media_test_unidades_naturales2
```

De nuevo, calculamos la diferencia entre el precio predicho y el real, y hallamos la media. En este caso, la diferencia media es de 132696.9$, muy similar a la anterior. Podemos concluir que el modelo es bueno.


# Conclusiones y líneas futuras

## Conclusiones

Por último, concluimos lo siguiente:

- Tras el análisis exploratorio, se deduce que las variables bedrooms, bathrooms, sqft_living, sqft_above, sqft_basement, waterfront, view, grade y yr_renovated, son variables que poseen una relación lineal muy clara con price. Sin embargo, sqft_lot, floors, condition y yr_built, son variables que no tienen una relación tan clara. Además, se observa que sqft_living15 y sqft_lot15 aportan una información muy similar a sqft_living y sqft_lot, por lo que no las tuvimos en cuenta.

- Para medir la correlación entre las variables, se calcula la matriz de correlación y se observa que las variables con mayor correlación con la variable respuesta price son: bathrooms, sqft_living, sqft_above y lat. También se concluye que sqft_living y sqft_above están altamente correlacionadas entre sí, por lo que para el modelo no las consideramos conjuntamente.

- Se ha realizado el reescalado de las variables y hemos visto que obteníamos los mismos resultados, por lo que se ha decidido continuar el estudio sin reescalar.

- Tras los dos análisis anteriores, y después de realizar varias pruebas para implementar el mejor modelo, concluimos que las variables más apropiadas para un modelo de regresión lineal son: bathrooms, sqft_living, lat y waterfront. El modelo elegido, tiene asociado un *Adjusted R-squared* de 0.68, es decir, puede explicar un 68% de la variabilidad observada en el precio de las casas.

- Finalmente, con los datos de test y validación, comprobamos que el modelo seleccionado predice los precios con una diferencia media respecto al precio real de aproximadamente 133.000$. 

## Líneas futuras

Con la información obtenida de la selección de variables automática, y los resultados del modelo, se podrían plantear como trabajos futuros, la recategorización de algunas variables, como por ejemplo, view. Rechazamos el modelo 1b, aunque poseía mejores métricas que el modelo 2, porque view introducía 4 variables dummies y waterfront solo 1. Podría analizarse si view podría agruparse de otro modo.

También se podría estudiar cómo se relaciona yr_built con price, y si podría aportar información al modelo. Lo mismo ocurre con zipcode, esta variable no la hemos considerado a estudio por poseer múltiples categorías, pero quizá agrupándola en subcategorías podría ser otra variable a considerar para el modelo.

Por último, hemos comprobado que con un modelo de regresión lineal no llega a precisar todo lo que nos gustaría, por lo que podemos probar si aplicando otros modelos se podrían conseguir mejores resultados. 

# Categorizar la variable respuesta

```{r}

datos_train_knn <- datos_train[c(1,2,3,22,23,6,7:10,25,12,24,17:20,26)]

datos_train_knn <- datos_train_knn[,-2] %>% 
  select_if(is.numeric) %>% 
  scale(center = TRUE,scale = TRUE)
#datos_train_knn

distancias <- dist(datos_train_knn[500,])
```

```{r}
model <- stats::kmeans(distancias,2)

# summary(datos_train$price)
# # partimos en 450000
# datos_train_knn$price_categ <- cut(datos_train_knn$price,breaks = c(-1,450000,5000000),labels=c(0,1))
# 
# datos_train_knn$price = NULL
# table(datos_train_knn$price_categ)


```

```{r}
plot(distancias,col=model$cluster)
```
