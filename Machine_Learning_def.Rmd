---
title: "Machine learning"
author: "Natalia Alonso, Beatriz Martín y Susana Albarrán"
date: "7/2/2020"
output:
  html_document:
    code_folding: show
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
fig_caption: yes
---


```{r, lectura_datos, include=FALSE}
datos <- read.csv("kc_house_data.csv")
```

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lattice)
library(dplyr)
library(VIM)
library(mice)
library(DMwR2)
library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)
library(GGally)
library(ggplot2)
library(corrplot)
library(vcd)
library(DT)
library(gridExtra)
library(jpeg)
library(car)
library(leaflet)
library(scales)
library(cowplot)
library(useful)
library(rpart)
library(rattle)
library(class)
library(cluster)
library(rpart)
library(rpart.plot)
library(rattle)
library(caret)
library(randomForest)

```


# Introducción

Los datos que se van a analizar en este proyecto han sido obtenidos desde Kaggle. Contienen precios de casas que fueron vendidas desde mayo de 2014 hasta mayo de 2015 en **King County** que es un condado ubicado en el estado estadounidense de Washington. 

# Objetivo del estudio

Lo que queremos hacer con estos datos es predecir el precio de las casas dependiendo de los datos recogidos.


# Datos


## Categorización del precio

En nuestro estudio inicial, la variable **"Precio"** es continua, por lo que vamos a categorizarla. Se van a realizar dos tipos de cetegorizaciones:

-  **Categorización_1**: se ha categorizado en dos grupos, **B1**, casas baratas (casas con un precio inferior a 500.000) y casas caras, ***C1** (precio> 500.000)
- **Categorización2**: se ha categorizado en tres grupos, **B2**, casas baratas (casas con un precio < 330.000), casas precio medio, **M2** (330.000<precio< 650.000) y casas caras, ***C2** (precio> 650.000

Para decidir las categorizaciones se ha optado por los cuantiles.

```{r}
#Categorizamos la variable respuesta price:
quantile(datos$price, prob=seq(0, 1, length = 5))
datos$price_categ1 <- cut(datos$price, breaks = c(0, 500000, 100000000), labels = c("B1", "C1"))
table(datos$price_categ1)

datos$price_categ2 <- cut(datos$price, breaks = c(0, 330000, 650000, 100000000), labels = c("B2","M2", "C2"))
table(datos$price_categ2)

```

A continuación se muestran cómo están categorizados los datos:

```{r, fig.align='center', warning=FALSE}

#Categorizamos la variable respuesta price: histogramas

tabla_categ1<-table(datos$price_categ1)
barplot(tabla_categ1, main= "Categorización_1 del precio", xlab="precio_categ1",ylab="Nº de casas", col = c("green", "red"))


tabla_categ2<-table(datos$price_categ2)
barplot(tabla_categ2,main="Categorización_2 del precio", xlab="precio_categ2",ylab="Nº de casas", col = c("green", "red", "purple")) 



```


## Train, test y validación

Se va a separar los datos en los 3 conjuntos de datos fundamentales:  

-  Conjunto de datos de **entrenamiento**: en nuestro estudio **datos_train**, se corresponde con el 70% del total de los datos.
-  Conjunto de datos de **validación**: en nuestro estudio **datos_validacion**, se corresponde con el 15% del total de los datos.
-  Conjunto de datos de **test**: en nuestro estudia **datos_test**, se corresponde con el 15% del total de los datos.


```{r, fig.align='center', warning=FALSE}

num_total=nrow(datos)
set.seed(122556) #reproductividad

# 70% para train
indices_train = sample(1:num_total, .7*num_total)
datos_train = datos[indices_train,]

# 15% para test
indices=seq(1:num_total)
indices_test=indices[-indices_train]
indices_test1 = sample(indices_test, .15*num_total)
datos_test = datos[indices_test1,]

# 15% para validacion
indices_validacion=indices[c(-indices_train,-indices_test1)]
datos_validacion=datos[indices_validacion,]

```


## Análisis exploratorio de datos train

```{r, fig.align='center', warning=FALSE}
datos_train <- datos_train[,-2]

datos_train$id <- as.factor(datos_train$id)

datos_train$bathrooms_group <- cut(datos_train$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_train$bathrooms_group <- as.numeric(as.character(datos_train$bathrooms_group))

datos_train$log_sqft_living <- log10(datos_train$sqft_living)
datos_train$log_lot <- log10(datos_train$sqft_lot)
datos_train$log_above <- log10(datos_train$sqft_above)

datos_train$sqft_basement_cat <- cut(datos_train$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_train$waterfront<-as.factor(datos_train$waterfront)

datos_train$view<-as.factor(datos_train$view)

datos_train$condition<-as.factor(datos_train$condition)

datos_train$grade_categ <- cut(datos_train$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_train$yr_renovated_catg <-cut(datos_train$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_train$zipcode<-as.factor(datos_train$zipcode)

```

### Eliminación de Outliers

```{r, fig.align='center', warning=FALSE}
datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_habitaciones<-datos_train[datos_train$bedrooms==0,]$posicion
datos_train<-datos_train[-indices_cero_habitaciones,]

datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_banos<-datos_train$posicion[datos_train$bathrooms_group==0]
datos_train<-datos_train[-indices_cero_banos,]

datos_train$posicion<-c(1:nrow(datos_train))
indice_hab33 <- datos_train[datos_train$bedrooms==33,]$posicion
datos_train[datos_train$posicion == indice_hab33,]$bedrooms = 3
```


```{r}
datos_train_limpio <- datos_train[c(3,23:27,8:10,28,16:18,29,21,22)]
datos_train_numeric <- datos_train_limpio %>% select_if(is.numeric)
```

## Análisis exploratorio de datos Test

Realizamos todas las transformaciones y categorizaciones para el conjunto de datos de test.

```{r, fig.align='center', warning=FALSE}

datos_test <- datos_test[,-2]

datos_test$id <- as.factor(datos_test$id)

datos_test$bathrooms_group <- cut(datos_test$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_test$bathrooms_group <- as.numeric(as.character(datos_test$bathrooms_group))

datos_test$log_sqft_living <- log10(datos_test$sqft_living)
datos_test$log_lot <- log10(datos_test$sqft_lot)
datos_test$log_above <- log10(datos_test$sqft_above)

datos_test$sqft_basement_cat <- cut(datos_test$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_test$waterfront<-as.factor(datos_test$waterfront)

datos_test$view<-as.factor(datos_test$view)

datos_test$condition<-as.factor(datos_test$condition)

datos_test$grade_categ <- cut(datos_test$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_test$yr_renovated_catg <-cut(datos_test$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_test$zipcode<-as.factor(datos_test$zipcode)

datos_test_limpio <- datos_test[c(3,23:27,8:10,28,16:18,29,21,22)]
datos_test_numeric <- datos_test_limpio %>% select_if(is.numeric)
```

## Análisis exploratorio datos Validación

Realizamos todas las transformaciones y categorizaciones para el conjunto de datos de Validación.

```{r, fig.align='center', warning=FALSE}

datos_validacion <- datos_validacion[,-2]

datos_validacion$id <- as.factor(datos_validacion$id)

datos_validacion$bathrooms_group <- cut(datos_validacion$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_validacion$bathrooms_group <- as.numeric(as.character(datos_validacion$bathrooms_group))

datos_validacion$log_sqft_living <- log10(datos_validacion$sqft_living)
datos_validacion$log_lot <- log10(datos_validacion$sqft_lot)
datos_validacion$log_above <- log10(datos_validacion$sqft_above)

datos_validacion$sqft_basement_cat <- cut(datos_validacion$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_validacion$waterfront<-as.factor(datos_validacion$waterfront)

datos_validacion$view<-as.factor(datos_validacion$view)

datos_validacion$condition<-as.factor(datos_validacion$condition)

datos_validacion$grade_categ <- cut(datos_validacion$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_validacion$yr_renovated_catg <-cut(datos_validacion$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_validacion$zipcode<-as.factor(datos_validacion$zipcode)

datos_validacion_limpio <- datos_validacion[c(3,23:27,8:10,28,16:18,29,21,22)]

datos_validacion_numeric <- datos_validacion_limpio %>% select_if(is.numeric)

```

En este mapa se puede visualizar cómo se distribuyen las casas **"Caras"** y **"Baratas"**. Se observa que las casas que están cercanas al agua y a cerca de Seattle por la parte Norte, son más caras y hacia el sur más baratas.

```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red"), 
                       datos_train_limpio$price_categ1 )

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(datos_train_limpio$price_categ1))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~datos_train_limpio$price_categ1,
            title = "Tipos de Casas",
            opacity = 1)

```


# Métodos de agrupamiento -No supervisado

## K-Means

### Train

```{r}
colores1= c("red","blue")
colores11 = colores1[datos_train_limpio$price_categ1]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(datos_train_limpio$price_categ1), col=colores11)

colores2= c("red","blue","green")
colores22 = colores2[datos_train_limpio$price_categ2]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(datos_train_limpio$price_categ2), col=colores22)

```

A continuación realizamos el clustering:

```{r}
datos_scale<- as.data.frame(scale(datos_train_numeric))
set.seed(1234)
modelkm1 <- kmeans(datos_scale, centers=2)

#modelkm2 <- kmeans(datos_scale, centers=3)
#modelkm

#table(modelkm2$cluster) #asignación de observación a los cluster
# modelkm1$totss  #Inercia total
# modelkm1$betweenss  #Inercia inter grupos
# modelkm1$withinss   #Inercia intra grupos
# modelkm1$tot.withinss  #inercia total intra grupos

```

```{r}
colores1= c("red","blue")
colores11 = colores1[datos_train_limpio$price_categ1]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(modelkm1$cluster), col=colores11)

# colores2= c("red","blue","green")
# colores22 = colores2[datos_train_limpio$price_categ2]
# 
# plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n")
# text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(modelkm2$cluster), col=colores22)
```


```{r}

clusterkmeans=as.data.frame(modelkm1$cluster)

clusterkmeans$indice= as.integer(rownames(clusterkmeans))

colnames(clusterkmeans)[1]= "categoria_price_km"
clustering1= clusterkmeans[order(clusterkmeans$indice),]
```


Se visualiza como se reparten las casas según el agrupamiento que se ha realizado con K-Means:

```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal1 <- colorFactor(c("green","red"), 
                       clustering1$categoria_price_km )

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal1(clustering1$categoria_price_km))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal1 , values = ~clustering1$categoria_price_km,
            title = "Tipos de casas",
            opacity = 1)

```

Cómo se observa en el mapa, y si lo comparamos con el de los datos iniciales, dista bastante. Por lo que deducimos que la agrupación que está relalizando K-Means no es muy buena.

#### Evaluación del modelo

```{r}
tabla2=table(datos_train_limpio[,15],modelkm1$cluster)
#caras
pred.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[1,2])
rec.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
#baratas
pred.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[2,1])
rec.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
accuracy = (tabla2[1,1]+tabla2[2,2]) / (tabla2[1,1]+tabla2[1,2]+tabla2[2,1]+tabla2[2,2])
accuracy
```

#### Test

#### Validación

## K-Medoids 



```{r}

datoskmedoids = datos_train_limpio[,c(-15,-16)]

wbPam = pam(x = datoskmedoids, k = 2, keep.diss = TRUE,
keep.data = TRUE)

wbPam$medoids


plot(wbPam, main = "silhouette plot")
```

```{r}
#wbPam$clustering
#clustering= sort(wbPam$clustering)

clustering=as.data.frame(wbPam$clustering)

clustering$indice= as.integer(rownames(clustering))

colnames(clustering)[1]= "categoria_price"
clustering2= clustering[order(clustering$indice),]

```


```{r, fig.align='center', warning=FALSE}

center_lon = median(datoskmedoids$long,na.rm = TRUE)
center_lat = median(datoskmedoids$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red"), 
                       clustering2$categoria_price )

leaflet(datoskmedoids) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(clustering2$categoria_price))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~clustering2$categoria_price,
            title = "Tipos de casas",
            opacity = 1)

```


# Técnicas de reducción de la dimensionalidad:

## PCA

Es un método que permite simplificar la complejidad de espacios muestrales con muchas dimensiones a la vez que conserva su información.

```{r}

pca<-prcomp(datos_train_numeric,scale=T)
plot(prcomp(datos_train_numeric,scale=T))

#pca$center para saber la media de cada variable
#pca$scale para saber la desv.típica de cada variable

```

```{r}
 summary(prcomp(datos_test_numeric, scale=T))
biplot(x = pca, scale = 0, cex = 0.6, col = c("blue4", "brown3"))
```

# Aprendizaje supervisado 

## Modelo Lineales generalizados.

### Regresión logística

#### Train

```{r}

datos_train_rl=datos_train_limpio[,-16]

model_glm = glm(price_categ1 ~ bedrooms + bathrooms_group + log_sqft_living + log_lot + log_above + lat + long, family = binomial,
data =datos_train_rl )
summary(model_glm)


```

```{r}

#ggplot(subset(datos_train_rl, select = c(bedrooms,bathrooms_group, #log_sqft_living, log_lot, log_above, lat, long, price_categ1)), aes(x = #bathrooms_group,
#y = price_categ1)) + geom_point() +  # geom_smooth(method = 'glm', method.args = list(family =
# 'binomial'), se=FALSE) +
#geom_line(data = data.frame(bathrooms_group = data.frame(bathrooms_group = #seq(1,8,1)), price_categ1 = predict(model_glm, data.frame(bathrooms_group = #seq(1,8,1)), type = "response")), colour = "navy")


```



## KNN


Ver con cuantos vecinos:

```{r}

suppressWarnings(suppressMessages(library(kknn)))
modelo <- train.kknn(price_categ1 ~ ., data = datos_train_limpio, kmax = 10)
modelo

```


#### Train

```{r}
#k=1
#train
constante = 1
knn.train1=knn.cv(scale(datos_train_numeric),cl=as.factor(datos_train_limpio[,15]),k=constante)
tabla.knn.train1=table(knn.train1,datos_train_limpio[,15])
pred.knn.train1=tabla.knn.train1[2,2]/(tabla.knn.train1[2,2]+tabla.knn.train1[1,2])
rec.knn.train1=tabla.knn.train1[2,2]/(tabla.knn.train1[2,2]+tabla.knn.train1[2,1])
F_medida.knn.train1=(5*pred.knn.train1*rec.knn.train1)/(4*pred.knn.train1+rec.knn.train1)
F_medida.knn.train1
tabla.knn.train1
```

```{r}
#k=2
#train
knn.train2=knn.cv(scale(datos_train_numeric),cl=as.factor(datos_train_limpio[,15]),k=2)
tabla.knn.train2=table(knn.train2,datos_train_limpio[,15])
pred.knn.train2=tabla.knn.train2[2,2]/(tabla.knn.train2[2,2]+tabla.knn.train2[1,2])
rec.knn.train2=tabla.knn.train2[2,2]/(tabla.knn.train2[2,2]+tabla.knn.train2[2,1])
F_medida.knn.train2=(5*pred.knn.train2*rec.knn.train2)/(4*pred.knn.train2+rec.knn.train2)
F_medida.knn.train2
tabla.knn.train2

```


```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal1 <- colorFactor(c("green","red"), 
                       knn.train2)

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal1(knn.train2))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal1 , values = ~knn.train2,
            title = "Precio (en miles de $)",
            opacity = 1)

```

```{r}

tabla2=table(datos_train_limpio[,15],knn.train2)

#caras
pred.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[1,2])
rec.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2

```

```{r}
#baratas
pred.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[2,1])
rec.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
accuracy = (tabla2[1,1]+tabla2[2,2]) / (tabla2[1,1]+tabla2[1,2]+tabla2[2,1]+tabla2[2,2])
accuracy
```



#### Test

```{r}

knn.test2=knn(scale(datos_train_numeric),scale(datos_test_numeric),cl=datos_train_limpio[,15],k=2)

tabla2_test=table(datos_test_limpio[,15],knn.test2)
#caras
pred.means2=tabla2_test[2,2]/(tabla2_test[2,2]+tabla2_test[1,2])
rec.means2=tabla2_test[2,2]/(tabla2_test[2,2]+tabla2_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_test


```

```{r}
#baratas
pred.means2=tabla2_test[1,1]/(tabla2_test[1,1]+tabla2_test[2,1])
rec.means2=tabla2_test[1,1]/(tabla2_test[1,1]+tabla2_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_test
```

```{r}
accuracy = (tabla2_test[1,1]+tabla2_test[2,2]) / (tabla2_test[1,1]+tabla2_test[1,2]+tabla2_test[2,1]+tabla2_test[2,2])
accuracy
```


#### Validación

```{r}

knn.val=knn(scale(datos_train_numeric),scale(datos_validacion_numeric),cl=datos_train_limpio[,15],k=2)

tabla2_val=table(datos_validacion_limpio[,15],knn.val)
#caras
pred.means2=tabla2_val[2,2]/(tabla2_val[2,2]+tabla2_val[1,2])
rec.means2=tabla2_val[2,2]/(tabla2_val[2,2]+tabla2_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_val
```

```{r}
#baratas
pred.means2=tabla2_val[1,1]/(tabla2_val[1,1]+tabla2_val[2,1])
rec.means2=tabla2_val[1,1]/(tabla2_val[1,1]+tabla2_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_val
```

```{r}
accuracy = (tabla2_val[1,1]+tabla2_val[2,2]) / (tabla2_val[1,1]+tabla2_val[1,2]+tabla2_val[2,1]+tabla2_val[2,2])
accuracy
```

### Decision Trees

#### Train

```{r}
datos_train_limpio_dt=datos_train_limpio[,c(-11,-16)]

```


```{r}
decisiontree_model=rpart(price_categ1~., data=datos_train_limpio_dt,parms=list(split="gini") )
#resumen=summary(decisiontree_model)
print(decisiontree_model)

#kk=as.data.frame(summary(decisiontree_model))

fancyRpartPlot(decisiontree_model)
#rpart.plot(decisiontree_model)
#prp(decisiontree_model, type = 2, extra = 6, split.font = 3)

```

```{r}

tabla.train.arbol1=table(obs = datos_train_limpio_dt$price_categ1, pred = predict(decisiontree_model, type = "class") )

tabla.train.arbol1

```

```{r}
#caras
pred.means2=tabla.train.arbol1[2,2]/(tabla.train.arbol1[2,2]+tabla.train.arbol1[1,2])
rec.means2=tabla.train.arbol1[2,2]/(tabla.train.arbol1[2,2]+tabla.train.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.train.arbol1
```

```{r}
#baratas
pred.means2=tabla.train.arbol1[1,1]/(tabla.train.arbol1[1,1]+tabla.train.arbol1[2,1])
rec.means2=tabla.train.arbol1[1,1]/(tabla.train.arbol1[1,1]+tabla.train.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.train.arbol1
```

```{r}
accuracy = (tabla.train.arbol1[1,1]+tabla.train.arbol1[2,2]) / (tabla.train.arbol1[1,1]+tabla.train.arbol1[1,2]+tabla.train.arbol1[2,1]+tabla.train.arbol1[2,2])
accuracy
```

#### Test

```{r}


tabla.test.arbol1=table(obs = datos_test_limpio$price_categ1, pred = predict(decisiontree_model,datos_test_limpio[,-16], type ="class"))

tabla.test.arbol1
#caras
pred.means2=tabla.test.arbol1[2,2]/(tabla.test.arbol1[2,2]+tabla.test.arbol1[1,2])
rec.means2=tabla.test.arbol1[2,2]/(tabla.test.arbol1[2,2]+tabla.test.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.test.arbol1


```

```{r}
#baratas
pred.means2=tabla.test.arbol1[1,1]/(tabla.test.arbol1[1,1]+tabla.test.arbol1[2,1])
rec.means2=tabla.test.arbol1[1,1]/(tabla.test.arbol1[1,1]+tabla.test.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.test.arbol1
```

```{r}
accuracy = (tabla.test.arbol1[1,1]+tabla.test.arbol1[2,2]) / (tabla.test.arbol1[1,1]+tabla.test.arbol1[1,2]+tabla.test.arbol1[2,1]+tabla.test.arbol1[2,2])
accuracy
```


#### Validacion

```{r}


tabla.validacion.arbol1=table(obs = datos_validacion_limpio$price_categ1, pred = predict(decisiontree_model,datos_validacion_limpio[,-16], type ="class"))

tabla.validacion.arbol1
#caras
pred.means2=tabla.validacion.arbol1[2,2]/(tabla.validacion.arbol1[2,2]+tabla.validacion.arbol1[1,2])
rec.means2=tabla.validacion.arbol1[2,2]/(tabla.validacion.arbol1[2,2]+tabla.validacion.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.validacion.arbol1


```

```{r}
#baratas
pred.means2=tabla.validacion.arbol1[1,1]/(tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[2,1])
rec.means2=tabla.validacion.arbol1[1,1]/(tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.validacion.arbol1
```

```{r}
accuracy = (tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[2,2]) / (tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[1,2]+tabla.validacion.arbol1[2,1]+tabla.validacion.arbol1[2,2])
accuracy
```

### Random Forest

#### Train

```{r}
randomforest_model=randomForest(price_categ1~., data=datos_train_limpio_dt,parms=list(split="gini") )
#resumen=summary(decisiontree_model)
print(randomforest_model)


#kk=as.data.frame(summary(decisiontree_model))

#fancyRpartPlot(decisiontree_model)
#rpart.plot(decisiontree_model)
#prp(decisiontree_model, type = 2, extra = 6, split.font = 3)

```

```{r}

tabla_randomforest=table(obs = datos_train_limpio_dt$price_categ1, pred = predict(randomforest_model, type = "class") )

tabla_randomforest

```

```{r}
#caras
pred.means2=tabla_randomforest[2,2]/(tabla_randomforest[2,2]+tabla_randomforest[1,2])
rec.means2=tabla_randomforest[2,2]/(tabla_randomforest[2,2]+tabla_randomforest[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest
```

```{r}
#baratas
pred.means2=tabla_randomforest[1,1]/(tabla_randomforest[1,1]+tabla_randomforest[2,1])
rec.means2=tabla_randomforest[1,1]/(tabla_randomforest[1,1]+tabla_randomforest[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest
```

```{r}
accuracy = (tabla_randomforest[1,1]+tabla_randomforest[2,2]) / (tabla_randomforest[1,1]+tabla_randomforest[1,2]+tabla_randomforest[2,1]+tabla_randomforest[2,2])
accuracy
```

```{r}

tabla_randomforest_test=table(obs = datos_test_limpio$price_categ1, pred = predict(randomforest_model,datos_test_limpio[,-16], type ="class"))
tabla_randomforest_test

#caras
pred.means2=tabla_randomforest_test[2,2]/(tabla_randomforest_test[2,2]+tabla_randomforest_test[1,2])
rec.means2=tabla_randomforest_test[2,2]/(tabla_randomforest_test[2,2]+tabla_randomforest_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_test


```

```{r}
#baratas
pred.means2=tabla_randomforest_test[1,1]/(tabla_randomforest_test[1,1]+tabla_randomforest_test[2,1])
rec.means2=tabla_randomforest_test[1,1]/(tabla_randomforest_test[1,1]+tabla_randomforest_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_test
```

```{r}
accuracy = (tabla_randomforest_test[1,1]+tabla_randomforest_test[2,2]) / (tabla_randomforest_test[1,1]+tabla_randomforest_test[1,2]+tabla_randomforest_test[2,1]+tabla_randomforest_test[2,2])
accuracy
```

#### Validacion

```{r}


tabla_randomforest_val=table(obs = datos_validacion_limpio$price_categ1, pred = predict(randomforest_model,datos_validacion_limpio[,-16], type ="class"))

tabla_randomforest_val
#caras
pred.means2=tabla_randomforest_val[2,2]/(tabla_randomforest_val[2,2]+tabla_randomforest_val[1,2])
rec.means2=tabla_randomforest_val[2,2]/(tabla_randomforest_val[2,2]+tabla_randomforest_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_val


```

```{r}
#baratas
pred.means2=tabla_randomforest_val[1,1]/(tabla_randomforest_val[1,1]+tabla_randomforest_val[2,1])
rec.means2=tabla_randomforest_val[1,1]/(tabla_randomforest_val[1,1]+tabla_randomforest_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_val
```

```{r}
accuracy = (tabla_randomforest_val[1,1]+tabla_randomforest_val[2,2]) / (tabla_randomforest_val[1,1]+tabla_randomforest_val[1,2]+tabla_randomforest_val[2,1]+tabla_randomforest_val[2,2])
accuracy
```


# Ideas

cambiar el modelo para que aumente 1000 más la variable respuesta

## para estructurarlo

Primero transformaciones de train, test validacion
Luego cada modelo por separado con su train y test y validacion

## objetivo

## concluisones

* nos quedamos con la acuracy ya que es la única medida que tiene en cuenta los aciertos de las casas caras y de las baratas (la F_medida no tiene en cuenta los TN y la sensibilidad y especificidad solo tienen en cuenta que acierte las caras o las baratas pero no que acierte en ambas)
