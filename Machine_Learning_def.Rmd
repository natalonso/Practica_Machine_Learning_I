---
title: "Machine learning"
author: "Natalia Alonso, Beatriz Martín y Susana Albarrán"
date: "7/2/2020"
output:
  html_document:
    code_folding: show
    number_sections: yes
    fig_height: 5
    fig_width: 8
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
fig_caption: yes
---


```{r, lectura_datos, include=FALSE}
datos <- read.csv("kc_house_data.csv")
```


```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lattice)
library(dplyr)
library(VIM)
library(mice)
library(DMwR2)
library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)
library(GGally)
library(ggplot2)
library(corrplot)
library(vcd)
library(DT)
library(gridExtra)
library(jpeg)
library(car)
library(leaflet)
library(scales)
library(cowplot)
library(useful)
library(rpart)
library(rattle)
library(class)
library(cluster)
library(rpart)
library(rpart.plot)
library(rattle)
library(caret)
library(randomForest)
library(e1071)
library(mgcv)
library(StatMatch)
library(visreg)
library(ROCR)

```


# Introducción

Los datos que se van a analizar en este proyecto han sido obtenidos desde Kaggle. Contienen precios de casas que fueron vendidas desde mayo de 2014 hasta mayo de 2015 en **King County** que es un condado ubicado en el estado estadounidense de Washington. 

# Objetivo del estudio

Lo que queremos hacer con estos datos es clasificar/predecir las viviendas conforme a su precio dependiendo de las variables recogidas de cada una. Para ello se implementarán varios modelos, comprobando cuáles de ellos funcionan mejor con los tipos de variables que contamos. Finalmente se evaluarán los modelos en base a distintas métricas.


# Datos

## Categorización del precio

En nuestro estudio inicial, la variable **"Precio"** es continua, por lo que vamos a categorizarla. Se van a realizar dos tipos de cetegorizaciones:

-  **Categorización_1**: se ha categorizado en dos grupos, **B1**, casas baratas (casas con un precio inferior a 500.000) y casas caras, ***C1** (precio> 500.000)
- **Categorización_2**: se ha categorizado en tres grupos, **B2**, casas baratas (casas con un precio < 330.000), casas con un precio medio, **M2** (330.000<precio< 650.000) y casas caras, ***C2** (precio> 650.000).

Para decidir las categorizaciones se ha optado por los cuantiles.

```{r}
#Categorizamos la variable respuesta price:
quantile(datos$price, prob=seq(0, 1, length = 5))
datos$price_categ1 <- cut(datos$price, breaks = c(0, 500000, 100000000), labels = c("B1", "C1"))
table(datos$price_categ1)

datos$price_categ2 <- cut(datos$price, breaks = c(0, 330000, 650000, 100000000), labels = c("B2","M2", "C2"))
table(datos$price_categ2)

```


En este mapa se puede visualizar cómo se distribuyen las casas **"Caras"** y **"Baratas"**. Se observa que las casas que están cercanas al agua y cerca de Seattle por la parte Norte, son más caras y hacia el sur más baratas.

```{r, fig.align='center', warning=FALSE}

center_lon = median(datos$long,na.rm = TRUE)
center_lat = median(datos$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red"), 
                       datos$price_categ1 )

leaflet(datos) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(datos$price_categ1))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~datos$price_categ1,
            title = "Tipos de Casas",
            opacity = 1)

```

En este otro mapa se puede visualizar cómo se distribuyen las casas según el precio en tres categorías:**"Caras"**, **Medio** y **"Baratas"**. 

```{r, fig.align='center', warning=FALSE}

center_lon = median(datos$long,na.rm = TRUE)
center_lat = median(datos$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red","yellow"), 
                       datos$price_categ2 )

leaflet(datos) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(datos$price_categ2))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~datos$price_categ2,
            title = "Tipos de Casas 3 categorías",
            opacity = 1)

```


## Train, test y validación

Se va a separar los datos en los 3 conjuntos de datos fundamentales:  

-  Conjunto de datos de **entrenamiento**: en nuestro estudio **datos_train**, se corresponde con el 70% del total de los datos.
-  Conjunto de datos de **validación**: en nuestro estudio **datos_validacion**, se corresponde con el 15% del total de los datos.
-  Conjunto de datos de **test**: en nuestro estudio **datos_test**, se corresponde con el 15% del total de los datos.


```{r, fig.align='center', warning=FALSE}

num_total=nrow(datos)
set.seed(122556) #reproductividad

# 70% para train
indices_train = sample(1:num_total, .7*num_total)
datos_train = datos[indices_train,]

# 15% para test
indices=seq(1:num_total)
indices_test=indices[-indices_train]
indices_test1 = sample(indices_test, .15*num_total)
datos_test = datos[indices_test1,]

# 15% para validacion
indices_validacion=indices[c(-indices_train,-indices_test1)]
datos_validacion=datos[indices_validacion,]

```


## Análisis exploratorio

Se van a realizar transformaciones de un conjunto de variables, estas transformaciones se aplicarán a cada conjunto de datos, train, test y validación:

  - Se realiza una transformación logarítmica sobre las variables **sqft_living** (pies cuadrados de la casa), **sqft_lot** (pies cuadrados del jardín) y **sqft_above** (pies cuadrados poe encima del suelo), hay que aclarar que esta última variable es la diferencia entre **sqft_living** y **sqft_basement** por lo que va a estar altamentente correlada con sqft_living.

  - Se categorizan las variables:
  
    + **Bathroom**, esta varible puede tomar valores decimales de 0.25 en 0.25. El número de baños se contabiliza por las piezas y cada baño completo tiene 4 piezas, por lo que con la nueva agrupación toma valores de 1 a 8 baños.
  
    + **Sqft_basement**, se categoriza como 0 las casas que no tienen sótano y 1 las casas que sí tienen sótano. 
  
    + **Grade**, se va a categorizar del siguiente modo con valor 0=calidad Baja, 1= calidad media y 2= calidad alta.

    + **Year_renovated**,  se categoriza como  0 = no ha tenido renovación y 1 = sí ha tenido renovación.
 
  - Se pasan a factor las variables: **waterfront**, **view**, **condition**, **grade_categ** y **zipcode**.
  
  - Se eliminan Outliers.


### Transformaciones datos Train

```{r, fig.align='center', warning=FALSE}
datos_train <- datos_train[,-2]

datos_train$id <- as.factor(datos_train$id)

datos_train$bathrooms_group <- cut(datos_train$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_train$bathrooms_group <- as.numeric(as.character(datos_train$bathrooms_group))

datos_train$log_sqft_living <- log10(datos_train$sqft_living)
datos_train$log_lot <- log10(datos_train$sqft_lot)
datos_train$log_above <- log10(datos_train$sqft_above)

datos_train$sqft_basement_cat <- cut(datos_train$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_train$waterfront<-as.factor(datos_train$waterfront)

datos_train$view<-as.factor(datos_train$view)

datos_train$condition<-as.factor(datos_train$condition)

datos_train$grade_categ <- cut(datos_train$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_train$yr_renovated_catg <-cut(datos_train$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_train$zipcode<-as.factor(datos_train$zipcode)

```

#### Eliminación de Outliers

```{r, fig.align='center', warning=FALSE}
datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_habitaciones<-datos_train[datos_train$bedrooms==0,]$posicion
datos_train<-datos_train[-indices_cero_habitaciones,]

datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_banos<-datos_train$posicion[datos_train$bathrooms_group==0]
datos_train<-datos_train[-indices_cero_banos,]

datos_train$posicion<-c(1:nrow(datos_train))
indice_hab33 <- datos_train[datos_train$bedrooms==33,]$posicion
datos_train[datos_train$posicion == indice_hab33,]$bedrooms = 3
```


### Transformaciones adicionales:

Se han realizado dos categorizaciones adicionales sobre el conjunto de datos. Después de implementar varios modelos, se llegó a la conclusión de que algunas variables podían mejorar los resultados de los modelos siendo agrupadas. Para analizar cómo recategorizar se ha usado un árbol de decisión. Las variables son:  **zipcode** y **bathrooms_group**.

- **Zipcode**, esta variable es de tipo factor y tenía 70 códigos postales, por lo que se ha decidido aplicar un arbol de decisión para ver cómo clasificaba los códigos postales y así volver a categorizarla según el resultado obtenido.

```{r}

model_selec_zipcode<-rpart(price_categ1~zipcode,data=datos_train ,parms=list(split="gini"))
print(model_selec_zipcode)

```

Se va a categorizar en dos Zona1 y Zona2.

```{r}

datos_train$zona<-recode(datos_train$zipcode, "98001=1; 98002=1; 98003=1; 98010=1; 98011=1; 98014=1; 98019=1; 98022=1; 98023=1; 98024=1; 98028=1; 98030=1; 98031=1; 98032=1; 98034=1; 98038=1; 98042=1; 98045=1; 98055=1; 98056=1; 98058=1; 98059=1; 98070=1; 98092=1 ;98106=1; 98108=1; 98118=1; 98125=1; 98126=1; 98133=1; 98144=1; 98146=1; 98148=1; 98155=1; 98166=1; 98168=1; 98178=1; 98188=1; 98198=1; 98004=2; 98005=2; 98006=2; 98007=2; 98008=2; 98027=2; 98029=2; 98033=2; 98039=2; 98040=2; 98052=2; 98053=2; 98065=2; 98072=2; 98074=2; 98075=2; 98077=2; 98102=2; 98103=2; 98105=2; 98107=2; 98109=2; 98112=2; 98115=2; 98116=2; 98117=2; 98119=2; 98122=2; 98136=2; 98177=2; 98199=2")

datos_train$zipcode = NULL

```

- **bathrooms_group**, se aplica el mismo método que con zipcode para ver cómo se puede categorizar esta variable. Toma valores de 1 a 8 y queremos reducir el número de niveles.


```{r}

model_selec_bathrooms<-rpart(price_categ1~bathrooms_group,data=datos_train ,parms=list(split="gini"))
print(model_selec_bathrooms)

```

En el resultado del modelo se ve que corta en el número de baños < 2.5, por lo que se va a categorizar como 0 aquellas casas que tengan de 1 a 2 baños y como 1 las casas que tengan más de 2 baños.

```{r}

datos_train$bathrooms_group <- cut(datos_train$bathrooms_group, breaks = c(-1,2.5,8),labels=c(0,1))
#0: 1 ó 2 baños; 1: + de 3 baños.

```


```{r}

# Limpiamos el dataframe
datos_train_limpio <- datos_train[c(3,22:26,8:10,27,16,17,30,28,20,21)]

#Eliminamos sqft_above porque es una combinalción lineal de sqft_living, están altamente correladas........
datos_train_limpio$log_above = NULL

datos_train_numeric <- datos_train_limpio %>% select_if(is.numeric)
```



### Transformaciones datos Test

Realizamos todas las transformaciones y categorizaciones para el conjunto de datos de test.

```{r, fig.align='center', warning=FALSE}

datos_test <- datos_test[,-2]

datos_test$id <- as.factor(datos_test$id)

datos_test$bathrooms_group <- cut(datos_test$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_test$bathrooms_group <- as.numeric(as.character(datos_test$bathrooms_group))

datos_test$log_sqft_living <- log10(datos_test$sqft_living)
datos_test$log_lot <- log10(datos_test$sqft_lot)
datos_test$log_above <- log10(datos_test$sqft_above)

datos_test$sqft_basement_cat <- cut(datos_test$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_test$waterfront<-as.factor(datos_test$waterfront)

datos_test$view<-as.factor(datos_test$view)

datos_test$condition<-as.factor(datos_test$condition)

datos_test$grade_categ <- cut(datos_test$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_test$yr_renovated_catg <-cut(datos_test$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_test$zipcode<-as.factor(datos_test$zipcode)

#codificar la variable Zipcode

datos_test$zona<-recode(datos_test$zipcode, " 98001=1; 98002=1; 98003=1; 98010=1; 98011=1; 98014=1; 98019=1; 98022=1; 98023=1; 98024=1; 98028=1; 98030=1; 98031=1; 98032=1; 98034=1; 98038=1; 98042=1; 98045=1; 98055=1; 98056=1; 98058=1; 98059=1; 98070=1; 98092=1 ;98106=1; 98108=1; 98118=1; 98125=1; 98126=1; 98133=1; 98144=1; 98146=1; 98148=1; 98155=1; 98166=1; 98168=1; 98178=1; 98188=1; 98198=1; 98004=2; 98005=2; 98006=2; 98007=2; 98008=2; 98027=2; 98029=2; 98033=2; 98039=2; 98040=2; 98052=2; 98053=2; 98065=2; 98072=2; 98074=2; 98075=2; 98077=2; 98102=2; 98103=2; 98105=2; 98107=2; 98109=2; 98112=2; 98115=2; 98116=2; 98117=2; 98119=2; 98122=2; 98136=2; 98177=2; 98199=2")

datos_test$zipcode = NULL

datos_test$bathrooms_group <- cut(datos_test$bathrooms_group, breaks = c(-1,2.5,8),labels=c(0,1))

#0 1ó 2 baños, 1 de 3 baños en adelante
```



```{r}
datos_test_limpio <- datos_test[c(3,22:26,8:10,27,16,17,29,28,20,21)]
datos_test_limpio$log_above = NULL
datos_test_numeric <- datos_test_limpio %>% select_if(is.numeric)
```

## Transformaciones datos Validación

Realizamos todas las transformaciones y categorizaciones para el conjunto de datos de Validación.

```{r, fig.align='center', warning=FALSE}

datos_validacion <- datos_validacion[,-2]

datos_validacion$id <- as.factor(datos_validacion$id)

datos_validacion$bathrooms_group <- cut(datos_validacion$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_validacion$bathrooms_group <- as.numeric(as.character(datos_validacion$bathrooms_group))

datos_validacion$log_sqft_living <- log10(datos_validacion$sqft_living)
datos_validacion$log_lot <- log10(datos_validacion$sqft_lot)
datos_validacion$log_above <- log10(datos_validacion$sqft_above)

datos_validacion$sqft_basement_cat <- cut(datos_validacion$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_validacion$waterfront<-as.factor(datos_validacion$waterfront)

datos_validacion$view<-as.factor(datos_validacion$view)

datos_validacion$condition<-as.factor(datos_validacion$condition)

datos_validacion$grade_categ <- cut(datos_validacion$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_validacion$yr_renovated_catg <-cut(datos_validacion$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_validacion$zipcode<-as.factor(datos_validacion$zipcode)

#codificar la variable Zipcode

datos_validacion$zona<-recode(datos_validacion$zipcode, " 98001=1; 98002=1; 98003=1; 98010=1; 98011=1; 98014=1; 98019=1; 98022=1; 98023=1; 98024=1; 98028=1; 98030=1; 98031=1; 98032=1; 98034=1; 98038=1; 98042=1; 98045=1; 98055=1; 98056=1; 98058=1; 98059=1; 98070=1; 98092=1 ;98106=1; 98108=1; 98118=1; 98125=1; 98126=1; 98133=1; 98144=1; 98146=1; 98148=1; 98155=1; 98166=1; 98168=1; 98178=1; 98188=1; 98198=1; 98004=2; 98005=2; 98006=2; 98007=2; 98008=2; 98027=2; 98029=2; 98033=2; 98039=2; 98040=2; 98052=2; 98053=2; 98065=2; 98072=2; 98074=2; 98075=2; 98077=2; 98102=2; 98103=2; 98105=2; 98107=2; 98109=2; 98112=2; 98115=2; 98116=2; 98117=2; 98119=2; 98122=2; 98136=2; 98177=2; 98199=2")

datos_validacion$zipcode = NULL

datos_validacion$bathrooms_group <- cut(datos_validacion$bathrooms_group, breaks = c(-1,2.5,8),labels=c(0,1))

```

```{r}
datos_validacion_limpio <- datos_validacion[c(3,22:26,8:10,27,16,17,29,28,20,21)]
datos_validacion_limpio$log_above = NULL
datos_validacion_numeric <- datos_validacion_limpio %>% select_if(is.numeric)
```



```{r}
#Aquí nos cargamos ya price_categ2

datos_train_limpio$price_categ2= NULL
datos_test_limpio$price_categ2= NULL
datos_validacion_limpio$price_categ2 = NULL

```


# Métodos de agrupamiento-No supervisado

A continuación, se implementan dos métodos de agrupamiento no supervisado. Primero, un método jerárquico para averiguar (si es posible) la cantidad adecuada de clústeres y a continuación K-Means y K-Medoids.

## Cluster Jerárquico

La agrupación es una técnica para agrupar puntos de datos similares en un grupo y separar las diferentes observaciones en diferentes grupos. En el Clustering Jerárquico los clusters se crean de manera que tengan un orden predeterminado. En nuestro estudio se va a plicar un **método aglomerativo** que consiste en que cada observación se asigna a su propio clúster. Luego, se calcula la similitud (o distancia) entre cada uno de los clusters y los dos clusters más similares se fusionan en uno. Finalmente, los pasos 2 y 3 se repiten hasta que solo quede un grupo.

Aplicando este método a nuestros datos queremos observar si siguen algún patrón para poder agrupar las casas.

### Train

Escalamos las variables numéricas, es decir cada variable ahora tendrá una media cero y una desviación estándar uno.También se requieren los valores de distancia. La medida predeterminada para la función dist es ‘Euclidiana’.  

```{r}
datos_scale<- as.data.frame(scale(datos_train_numeric))

#Matriz de distancias
matriz_dist=dist(datos_scale)

```

En este caso particular, estimamos dos clústeres:

```{r}

modelo_hc= hclust(matriz_dist, method = "average")
plot(modelo_hc)
rect.hclust(modelo_hc, k=2,border="red")

```

A continuación vemos como se han agrupado los datos marcando que el número de clústeres sea 2. Prácticamente todas las casas están en el grupo 1.

```{r}

grupos2=cutree(modelo_hc,k=2)
table(datos_train_limpio$price_categ1, grupos2)

```


## Clúster no Jerárquico- K-Means

El método de **K-Means** basa su funcionamiento en agrupar los datos de entrada en un total de k conjuntos definidos por un centroide, cuya distancia con los puntos que pertenecen a cada uno de los datos sea la menor posible. 

### Train

Primero se van a realizar los gráficos para ver cómo están diferenciadas las casas por precio. Para poder visualizarlo en dos dimensiones se ha usado la función **"prcomp"** (PCA)

```{r}
colores1= c("red","blue")
colores11 = colores1[datos_train_limpio$price_categ1]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n",main= "Dos categorías")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(datos_train_limpio$price_categ1), col=colores11)

```

A continuación se va a aplicar el método de agrupamiento K-means, al igual que en el método anterior se le pasa la matriz de distacias y se van a agrupar los datos en dos conjuntos:

```{r}

set.seed(1234)
model_km <- kmeans(matriz_dist, centers=2)
table(model_km$cluster) #asignación de observación a los cluster

```



```{r}
colores1= c("red","blue")
colores11 = colores1[datos_train_limpio$price_categ1]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(model_km$cluster), col=colores11)

```


#### Cálculo del k-óptimo.

Se va a determinar la cantidad óptima de centroides a utilizar a partir del Método del Codo. Para ello, aplicaremos la función kmeans al conjunto de datos, variando en cada caso el valor de k, y acumulando los valores de WCSS (Within-Cluster-Sum-of-Squares) obtenidos:


```{r}

set.seed(1234)
wcss <- vector()
for(i in 1:20){
  wcss[i] <- sum(kmeans(datos_scale, i)$withinss)
}

ggplot() + geom_point(aes(x = 1:20, y = wcss), color = 'blue') + 
  geom_line(aes(x = 1:20, y = wcss), color = 'blue') + 
  ggtitle("Método del Codo") + 
  xlab('Cantidad de Centroides k') + 
  ylab('WCSS')


```


Como se observa en la gráfica, el K-óptimo que se podría aplicar sería de 10.

A continuación para visualizar si el agrupamiento que se ha llevado a cabo está relacionado con el precio de las casas (**"Caras"**, **Baratas**), se representa en el mapa que se muestra a continuación.


```{r}

clusterkmeans=as.data.frame(model_km$cluster)
clusterkmeans$indice= as.integer(rownames(clusterkmeans))

colnames(clusterkmeans)[1]= "categoria_price_km"
clustering1= clusterkmeans[order(clusterkmeans$indice),]


center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal1 <- colorFactor(c("green","red"),
                       clustering1$categoria_price_km )

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal1(clustering1$categoria_price_km))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal1 , values = ~clustering1$categoria_price_km,
            title = "Tipos de casas",
            opacity = 1)

```

Cómo se observa en el mapa, y si lo comparamos con el de los datos iniciales, dista bastante. Por lo que deducimos que la agrupación que está relalizando K-Means no es muy buena.



## K-Medoids

K-medoids es un método de clustering muy similar a K-means en cuanto a que ambos agrupan las observaciones en K clusters, donde K es un valor preestablecido. La diferencia es que, en K-medoids, cada cluster está representado por una observación presente en el cluster (medoid),en nuestro estudio será una observación de una casa, mientras que en K-means cada cluster está representado por su centroide, que se corresponde con el promedio de todas las observaciones del cluster pero con ninguna en particular.

Este algoritmo es menos sensible al ruido y los valores atípicos, en comparación con k-means, porque usa medoides como centros de clúster en lugar de centroides. (utilizados en k-means).


```{r}

datoskmedoids = datos_train_limpio[,-15]
model_medoids = pam(x = datoskmedoids, k = 2, keep.diss = TRUE, keep.data = TRUE)
model_medoids$medoids

```

```{r}
grupos<-data.frame(datoskmedoids)
grupos<-cbind(grupos,data.frame(model_medoids$clustering))
grupos$model_medoids.clustering<-as.factor(grupos$model_medoids.clustering)
ggpairs(grupos,columns=c(1,2,3,15,12),mapping=aes(color=model_medoids.clustering))
table(grupos$model_medoids.clustering)
```

```{r}

clustering= sort(model_medoids$clustering)
clustering=as.data.frame(model_medoids$clustering)
clustering$indice= as.integer(rownames(clustering))

colnames(clustering)[1]= "categoria_price"
clustering2= clustering[order(clustering$indice),]

center_lon = median(datoskmedoids$long,na.rm = TRUE)
center_lat = median(datoskmedoids$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red"), 
                       clustering2$categoria_price )

leaflet(datoskmedoids) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(clustering2$categoria_price))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~clustering2$categoria_price,
            title = "Tipos de casas",
            opacity = 1)

```


# Técnicas de reducción de la dimensionalidad:

## PCA

Es un método que permite simplificar la complejidad de espacios muestrales con muchas dimensiones a la vez que conserva su información.

```{r}
pca<-prcomp(datos_train_numeric,scale=T)
plot(pca)

```

```{r}
summary(pca)
biplot(x = pca, scale = 0, cex = 0.6, col = c("blue4", "brown3"))
```

# Aprendizaje supervisado 

## GLM-Regresión Logística.

Con este modelo se va a estudiar si existe relación entre el hecho de que una casa sea "cara" ó "barata" dependiendo de las características de las casas. Se va a generar un modelo en el que a partir de las variables prediga la probabilidad de que una casa sea barata o cara.


### Train

```{r}

datos_train_rl <- datos_train_limpio[,-c(8,9)] # quitamos condition y grade_categ (no aportan **)
datos_train_rl$price_categ1<- recode(datos_train_rl$price_categ1, "'B1'=0; 'C1'=1")

```


```{r}

model_glm = glm(price_categ1 ~., family = binomial, data =datos_train_rl )
summary(model_glm)

```


```{r}
# EVALUACION

predicciones <- ifelse(test = model_glm$fitted.values > 0.5, yes = 1, no = 0)
tabla_reglog <- table(model_glm$model$price_categ1, predicciones,
                          dnn = c("observaciones", "predicciones"))
tabla_reglog

#caras
pred.means2=tabla_reglog[2,2]/(tabla_reglog[2,2]+tabla_reglog[1,2])
rec.means2=tabla_reglog[2,2]/(tabla_reglog[2,2]+tabla_reglog[2,1])
F_caras_reglog=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
cat(c('F1 casas caras: ', F_caras_reglog), '\n')

#baratas
pred.means2=tabla_reglog[1,1]/(tabla_reglog[1,1]+tabla_reglog[2,1])
rec.means2=tabla_reglog[1,1]/(tabla_reglog[1,1]+tabla_reglog[1,2])
F_baratas_reglog=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
cat(c('F1 casas baratas: ', F_baratas_reglog), '\n')

#F-Medida
F_reglog_train= (F_caras_reglog+F_baratas_reglog)/2
cat(c('F1 global: ', F_reglog_train), '\n')

accuracy_reglog_train = (tabla_reglog[1,1]+tabla_reglog[2,2]) / (tabla_reglog[1,1]+tabla_reglog[1,2]+tabla_reglog[2,1]+tabla_reglog[2,2])
cat(c('Accuracy: ', accuracy_reglog_train), '\n')

```


## KNN

### Train

#### Ajuste de Hiperparámetros.


Hemos usado tres métodos para ajustar y comparar este modelo (parámetro k):

1. Usando **train.kknn**.
2. Usando **tune**.
3. Usando diferentes k de 1 a 50 y comprobando los resultados de la F1-medida.

En primer lugar con la función **train.kknn** se obtiene de manera automática el mejor valor de k hasta un máximo de k=30.

```{r}
set.seed(1234)

suppressWarnings(suppressMessages(library(kknn)))
knn_1 <- train.kknn(price_categ1 ~ ., data = datos_train_limpio, kmax = 30)
knn_1

```

En segundo lugar se usa la función **tune** que itera hasta k = 30 y muestra el error y la dispersión para cada valor de k.

```{r}
set.seed(1234)

knn_2 <- tune.knn(x=scale(datos_train_numeric),
                  y=as.factor(datos_train_limpio$price_categ1), k = 1:30,
                  tunecontrol = tune.control(sampling = "boot"))
summary(knn_2)
plot(knn_2)

```


En tercer lugar, se comprueba manualmente los resultados de la F1-medida con diferentes modelos desde k=1 hasta el k=50 y se representa el resultado.

```{r}
set.seed(1234)

k_maximo=50

rango=1:(k_maximo+10)
f1_modelos=c()

for (i in rango){
  model_knn=knn.cv(scale(datos_train_numeric),cl=as.factor(datos_train_limpio$price_categ1),k=i)
  tabla=table(datos_train_limpio$price_categ1,model_knn)
  # f1 casas caras
  pred_means_caras=tabla[2,2]/(tabla[2,2]+tabla[1,2])
  rec_means_caras=tabla[2,2]/(tabla[2,2]+tabla[2,1])
  f1_caras=(2*pred_means_caras*rec_means_caras)/(pred_means_caras+rec_means_caras)
  # f1 casas baratas
  pred_means_baratas=tabla[1,1]/(tabla[1,1]+tabla[2,1])
  rec_means_baratas=tabla[1,1]/(tabla[1,1]+tabla[1,2])
  f1_baratas=(2*pred_means_baratas*rec_means_baratas)/(pred_means_baratas+rec_means_baratas)
  f1_total = (f1_baratas + f1_caras)/2
  f1_modelos=c(f1_modelos,f1_total)
}


plot(f1_modelos)
cat(c('Valor óptimo de k: ', which.max(f1_modelos)))

```


De la primer forma obtenemos un valor óptimo de k=15, del segundo modo k = 27, y de la forma manual, concluimos que el mejor valor de k en función de la F1-medida es de k=17. Finalmente, elegimos el valor de k = 17, implementamos el modelo y lo evaluamos.

```{r}

model_knn=knn.cv(scale(datos_train_numeric),cl=as.factor(datos_train_limpio$price_categ1),k=17)

```






```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal1 <- colorFactor(c("green","red"), 
                       model_knn)

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal1(model_knn))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal1 , values = ~model_knn,
            title = "Precio (en miles de $)",
            opacity = 1)

```

```{r}

tabla_knn=table(datos_train_limpio$price_categ1,model_knn)
tabla_knn

#caras
pred_means_caras_knn=tabla_knn[2,2]/(tabla_knn[2,2]+tabla_knn[1,2])
rec_means_knn=tabla_knn[2,2]/(tabla_knn[2,2]+tabla_knn[2,1])
F_caras_knn_train=(2*pred_means_caras_knn*rec_means_knn)/(pred_means_caras_knn+rec_means_knn)
cat(c('F1 caras: ', F_caras_knn_train), '\n')

#baratas
pred_means_baratas_knn=tabla_knn[1,1]/(tabla_knn[1,1]+tabla_knn[2,1])
rec_means_baratas_knn=tabla_knn[1,1]/(tabla_knn[1,1]+tabla_knn[1,2])
F_baratas_knn_train=(2*pred_means_baratas_knn*rec_means_baratas_knn)/(pred_means_baratas_knn+rec_means_baratas_knn)
cat(c('F1 baratas: ', F_baratas_knn_train), '\n')


#Media de la F-MEDIDA para KNN
F_knn_train= (F_caras_knn_train+F_baratas_knn_train)/2
cat(c('F1 global: ', F_knn_train), '\n')


accuracy_knn_train= (tabla_knn[1,1]+tabla_knn[2,2]) / (tabla_knn[1,1]+tabla_knn[1,2]+tabla_knn[2,1]+tabla_knn[2,2])
cat(c('Accuracy: ', accuracy_knn_train), '\n')
```


### Test

```{r}

model_knn_test=knn(scale(datos_train_numeric),scale(datos_test_numeric),cl=datos_train_limpio$price_categ1,k=17)

tabla_knn_test=table(datos_test_limpio$price_categ1, model_knn_test)
tabla_knn_test

#caras
pred_means_caras_knn_test=tabla_knn_test[2,2]/(tabla_knn_test[2,2]+tabla_knn_test[1,2])
rec_means_knn_test=tabla_knn_test[2,2]/(tabla_knn_test[2,2]+tabla_knn_test[2,1])
F_caras_knn_test=(2*pred_means_caras_knn_test*rec_means_knn_test)/(pred_means_caras_knn_test+rec_means_knn_test)
cat(c('F1 caras: ', F_caras_knn_test), '\n')

#baratas
pred_means_baratas_knn_test=tabla_knn_test[1,1]/(tabla_knn_test[1,1]+tabla_knn_test[2,1])
rec_means_baratas_knn_test=tabla_knn_test[1,1]/(tabla_knn_test[1,1]+tabla_knn_test[1,2])
F_baratas_knn_test=(2*pred_means_baratas_knn_test*rec_means_baratas_knn_test)/(pred_means_baratas_knn_test+rec_means_baratas_knn_test)
cat(c('F1 baratas: ', F_baratas_knn_test), '\n')


#Media de la F-MEDIDA para KNN
F_knn_test = (F_caras_knn_test+F_baratas_knn_test)/2
cat(c('F1 global: ', F_knn_test), '\n')


accuracy_knn_test= (tabla_knn_test[1,1]+tabla_knn_test[2,2]) / (tabla_knn_test[1,1]+tabla_knn_test[1,2]+tabla_knn_test[2,1]+tabla_knn_test[2,2])
cat(c('Accuracy: ', accuracy_knn_test), '\n')
```


### Validación

```{r}
model_knn_validacion=knn(scale(datos_train_numeric),scale(datos_validacion_numeric),cl=datos_train_limpio$price_categ1,k=17)

tabla_knn_validacion=table(datos_validacion_limpio$price_categ1, model_knn_validacion)
tabla_knn_validacion

#caras
pred_means_caras_knn_validacion=tabla_knn_validacion[2,2]/(tabla_knn_validacion[2,2]+tabla_knn_validacion[1,2])
rec_means_knn_validacion=tabla_knn_validacion[2,2]/(tabla_knn_validacion[2,2]+tabla_knn_validacion[2,1])
F_caras_knn_validacion=(2*pred_means_caras_knn_validacion*rec_means_knn_validacion)/(pred_means_caras_knn_validacion+rec_means_knn_validacion)
cat(c('F1 caras: ', F_caras_knn_validacion), '\n')

#baratas
pred_means_baratas_knn_validacion=tabla_knn_validacion[1,1]/(tabla_knn_validacion[1,1]+tabla_knn_validacion[2,1])
rec_means_baratas_knn_validacion=tabla_knn_validacion[1,1]/(tabla_knn_validacion[1,1]+tabla_knn_validacion[1,2])
F_baratas_knn_validacion=(2*pred_means_baratas_knn_validacion*rec_means_baratas_knn_validacion)/(pred_means_baratas_knn_validacion+rec_means_baratas_knn_validacion)
cat(c('F1 baratas: ', F_baratas_knn_validacion), '\n')


#Media de la F-MEDIDA para KNN
F_knn_validacion = (F_caras_knn_validacion+F_baratas_knn_validacion)/2
cat(c('F1 global: ', F_knn_validacion), '\n')


accuracy_knn_validacion= (tabla_knn_validacion[1,1]+tabla_knn_validacion[2,2]) / (tabla_knn_validacion[1,1]+tabla_knn_validacion[1,2]+tabla_knn_validacion[2,1]+tabla_knn_validacion[2,2])
cat(c('Accuracy: ', accuracy_knn_validacion), '\n')

```

## Decision Trees

### Train


```{r}

#quitamos lat y long:
datos_decision_tree<-datos_train_limpio[,-c(11,12)]

decisiontree_model=rpart(price_categ1~., data=datos_decision_tree,parms=list(split="gini") )
#resumen=summary(decisiontree_model)
print(decisiontree_model)

#kk=as.data.frame(summary(decisiontree_model))

fancyRpartPlot(decisiontree_model)
#rpart.plot(decisiontree_model)
#prp(decisiontree_model, type = 2, extra = 6, split.font = 3)

```

```{r}

tabla_train_arbol=table(obs = datos_decision_tree$price_categ1, pred = predict(decisiontree_model, type = "class"))

tabla_train_arbol
```

```{r}
#caras
pred.means2=tabla_train_arbol[2,2]/(tabla_train_arbol[2,2]+tabla_train_arbol[1,2])
rec.means2=tabla_train_arbol[2,2]/(tabla_train_arbol[2,2]+tabla_train_arbol[2,1])
F_caras_dt_train=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_caras_dt_train
tabla_train_arbol
```

```{r}
#baratas
pred.means2=tabla_train_arbol[1,1]/(tabla_train_arbol[1,1]+tabla_train_arbol[2,1])
rec.means2=tabla_train_arbol[1,1]/(tabla_train_arbol[1,1]+tabla_train_arbol[1,2])
F_baratas_dt_train=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_baratas_dt_train
tabla_train_arbol
```
```{r}
#Media de la F-MEDIDA para Decision Tree
F_dt_train= (F_caras_dt_train+F_baratas_dt_train)/2
F_dt_train

```


```{r}
accuracy_dt_train = (tabla_train_arbol[1,1]+tabla_train_arbol[2,2]) / (tabla_train_arbol[1,1]+tabla_train_arbol[1,2]+tabla_train_arbol[2,1]+tabla_train_arbol[2,2])
accuracy_dt_train
```

### Test

```{r}


tabla.test.arbol1=table(obs = datos_test_limpio$price_categ1, pred = predict(decisiontree_model,datos_test_limpio[,-15], type ="class"))

tabla.test.arbol1
#caras
pred.means2=tabla.test.arbol1[2,2]/(tabla.test.arbol1[2,2]+tabla.test.arbol1[1,2])
rec.means2=tabla.test.arbol1[2,2]/(tabla.test.arbol1[2,2]+tabla.test.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.test.arbol1


```

```{r}
#baratas
pred.means2=tabla.test.arbol1[1,1]/(tabla.test.arbol1[1,1]+tabla.test.arbol1[2,1])
rec.means2=tabla.test.arbol1[1,1]/(tabla.test.arbol1[1,1]+tabla.test.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.test.arbol1
```

```{r}
accuracy = (tabla.test.arbol1[1,1]+tabla.test.arbol1[2,2]) / (tabla.test.arbol1[1,1]+tabla.test.arbol1[1,2]+tabla.test.arbol1[2,1]+tabla.test.arbol1[2,2])
accuracy
```


### Validacion

```{r}


tabla.validacion.arbol1=table(obs = datos_validacion_limpio$price_categ1, pred = predict(decisiontree_model,datos_validacion_limpio[,-15], type ="class"))

tabla.validacion.arbol1
#caras
pred.means2=tabla.validacion.arbol1[2,2]/(tabla.validacion.arbol1[2,2]+tabla.validacion.arbol1[1,2])
rec.means2=tabla.validacion.arbol1[2,2]/(tabla.validacion.arbol1[2,2]+tabla.validacion.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.validacion.arbol1


```

```{r}
#baratas
pred.means2=tabla.validacion.arbol1[1,1]/(tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[2,1])
rec.means2=tabla.validacion.arbol1[1,1]/(tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.validacion.arbol1
```

```{r}
accuracy = (tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[2,2]) / (tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[1,2]+tabla.validacion.arbol1[2,1]+tabla.validacion.arbol1[2,2])
accuracy
```

## Random Forest

### Train

```{r}
randomforest_model=randomForest(price_categ1~., data=datos_train_limpio,parms=list(split="gini") )
#print(randomforest_model)

```

```{r}

tabla_randomforest=table(obs = datos_train_limpio$price_categ1, pred = predict(randomforest_model, type = "class") )

tabla_randomforest

```

```{r}
#caras
pred.means2=tabla_randomforest[2,2]/(tabla_randomforest[2,2]+tabla_randomforest[1,2])
rec.means2=tabla_randomforest[2,2]/(tabla_randomforest[2,2]+tabla_randomforest[2,1])
F_caras_rf_train=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_caras_rf_train
tabla_randomforest
```

```{r}
#baratas
pred.means2=tabla_randomforest[1,1]/(tabla_randomforest[1,1]+tabla_randomforest[2,1])
rec.means2=tabla_randomforest[1,1]/(tabla_randomforest[1,1]+tabla_randomforest[1,2])
F_baratas_rf_train=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_baratas_rf_train
tabla_randomforest
```
```{r}
#Media de la F-MEDIDA para Random Forest
F_rf_train= (F_caras_rf_train+F_baratas_rf_train)/2
F_rf_train

```


```{r}
accuracy_rf_train = (tabla_randomforest[1,1]+tabla_randomforest[2,2]) / (tabla_randomforest[1,1]+tabla_randomforest[1,2]+tabla_randomforest[2,1]+tabla_randomforest[2,2])
accuracy_rf_train
```


### Test

```{r}

tabla_randomforest_test=table(obs = datos_test_limpio$price_categ1, pred = predict(randomforest_model,datos_test_limpio[,-15], type ="class"))
tabla_randomforest_test

#caras
pred.means2=tabla_randomforest_test[2,2]/(tabla_randomforest_test[2,2]+tabla_randomforest_test[1,2])
rec.means2=tabla_randomforest_test[2,2]/(tabla_randomforest_test[2,2]+tabla_randomforest_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_test


```

```{r}
#baratas
pred.means2=tabla_randomforest_test[1,1]/(tabla_randomforest_test[1,1]+tabla_randomforest_test[2,1])
rec.means2=tabla_randomforest_test[1,1]/(tabla_randomforest_test[1,1]+tabla_randomforest_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_test
```

```{r}
accuracy = (tabla_randomforest_test[1,1]+tabla_randomforest_test[2,2]) / (tabla_randomforest_test[1,1]+tabla_randomforest_test[1,2]+tabla_randomforest_test[2,1]+tabla_randomforest_test[2,2])
accuracy
```

### Validacion

```{r}


tabla_randomforest_val=table(obs = datos_validacion_limpio$price_categ1, pred = predict(randomforest_model,datos_validacion_limpio[,-15], type ="class"))

tabla_randomforest_val
#caras
pred.means2=tabla_randomforest_val[2,2]/(tabla_randomforest_val[2,2]+tabla_randomforest_val[1,2])
rec.means2=tabla_randomforest_val[2,2]/(tabla_randomforest_val[2,2]+tabla_randomforest_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_val


```

```{r}
#baratas
pred.means2=tabla_randomforest_val[1,1]/(tabla_randomforest_val[1,1]+tabla_randomforest_val[2,1])
rec.means2=tabla_randomforest_val[1,1]/(tabla_randomforest_val[1,1]+tabla_randomforest_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_val
```

```{r}
accuracy = (tabla_randomforest_val[1,1]+tabla_randomforest_val[2,2]) / (tabla_randomforest_val[1,1]+tabla_randomforest_val[1,2]+tabla_randomforest_val[2,1]+tabla_randomforest_val[2,2])
accuracy
```


## SVM

```{r}
modelo_svm <- e1071::svm(formula = price_categ1 ~., data = datos_train_limpio, kernel = "linear" , probability =TRUE)
summary(modelo_svm)

#plot(modelo_svm, datos_train_limpio_dt)
```
```{r}
#set.seed(1)
#tune.out = tune(svm,price_categ1 ~ ., data = datos_train_limpio_dt, kernel = "linear", ranges = list(cost = c(0.001,
#0.01, 0.1, 1, 5, 10, 100)))

```

### Train

```{r}

tabla_svm_train=table(obs = datos_train_limpio$price_categ1, pred = predict(modelo_svm,datos_train_limpio[,-15], type ="class"))

tabla_svm_train
#caras
pred.means2=tabla_svm_train[2,2]/(tabla_svm_train[2,2]+tabla_svm_train[1,2])
rec.means2=tabla_svm_train[2,2]/(tabla_svm_train[2,2]+tabla_svm_train[2,1])
F_caras_svm_train=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_caras_svm_train
tabla_svm_train


```

```{r}
#baratas
pred_means2=tabla_svm_train[1,1]/(tabla_svm_train[1,1]+tabla_svm_train[2,1])
rec_means2=tabla_svm_train[1,1]/(tabla_svm_train[1,1]+tabla_svm_train[1,2])
F_baratas_svm_train=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_baratas_svm_train
tabla_svm_train
```
```{r}
#F-Medida para SVM

F_svm_train= (F_caras_svm_train+F_baratas_svm_train)/2
F_svm_train

```


```{r}
accuracy_svm_train = (tabla_svm_train[1,1]+tabla_svm_train[2,2]) / (tabla_svm_train[1,1]+tabla_svm_train[1,2]+tabla_svm_train[2,1]+tabla_svm_train[2,2])
accuracy_svm_train
```

### Test

```{r}

tabla_svm_test=table(obs = datos_test_limpio$price_categ1, pred = predict(modelo_svm,datos_test_limpio[,-15], type ="class"))
tabla_svm_test

#caras
pred.means2=tabla_svm_test[2,2]/(tabla_svm_test[2,2]+tabla_svm_test[1,2])
rec.means2=tabla_svm_test[2,2]/(tabla_svm_test[2,2]+tabla_svm_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_test


```

```{r}
#baratas
pred.means2=tabla_svm_test[1,1]/(tabla_svm_test[1,1]+tabla_svm_test[2,1])
rec.means2=tabla_svm_test[1,1]/(tabla_svm_test[1,1]+tabla_svm_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_test
```

```{r}
accuracy = (tabla_svm_test[1,1]+tabla_svm_test[2,2]) / (tabla_svm_test[1,1]+tabla_svm_test[1,2]+tabla_svm_test[2,1]+tabla_svm_test[2,2])
accuracy
```

### Validacion

```{r}

tabla_svm_val=table(obs = datos_validacion_limpio$price_categ1, pred = predict(modelo_svm,datos_validacion_limpio[,-15], type ="class"))

tabla_svm_val
#caras
pred.means2=tabla_svm_val[2,2]/(tabla_svm_val[2,2]+tabla_svm_val[1,2])
rec.means2=tabla_svm_val[2,2]/(tabla_svm_val[2,2]+tabla_svm_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
```

```{r}
#baratas
pred.means2=tabla_svm_val[1,1]/(tabla_svm_val[1,1]+tabla_svm_val[2,1])
rec.means2=tabla_svm_val[1,1]/(tabla_svm_val[1,1]+tabla_svm_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_val
```

```{r}
accuracy = (tabla_svm_val[1,1]+tabla_svm_val[2,2]) / (tabla_svm_val[1,1]+tabla_svm_val[1,2]+tabla_svm_val[2,1]+tabla_svm_val[2,2])
accuracy
```



# GAM

### Train

```{r}
datos_train_gam <- datos_train_limpio
datos_train_gam$price <- datos_train$price
 
model_gam <- gam(price ~ s(bedrooms, bs = "cr") + bathrooms_group + s(log_sqft_living, bs = "cr") + 
                   s(log_lot, bs = "cr") + sqft_basement_cat + waterfront + view + s(lat, bs = "cr") + 
                   s(long, bs = "cr") + zona + yr_renovated_catg, data = datos_train_gam)

summary(model_gam)
plot(model_gam, ylab = "price")



par(mfrow=c(3,3))
visreg(model_gam)


```

### Test

```{r}
datos_test_limpio$price <- datos_test$price
datos_test_limpio$price_predict = predict(model_gam, datos_test_limpio)


datos_test_limpio$precio_diff <- abs(datos_test_limpio$price - datos_test_limpio$price_predict)

dif_media_test <- mean(datos_test_limpio$precio_diff)
dif_media_test

```

### Validación

```{r}
datos_validacion_limpio$price <- datos_validacion$price
datos_validacion_limpio$price_predict = predict(model_gam, datos_validacion_limpio)


datos_validacion_limpio$precio_diff <- abs(datos_validacion_limpio$price - datos_validacion_limpio$price_predict)

dif_media_test <- mean(datos_validacion_limpio$precio_diff)
dif_media_test
```


# Evaluación y comparación de modelos. 

Una vez que se han entrenado y optimizado distintos modelos, se tiene que identificar cuál de ellos consigue mejores resultados para el problema en cuestión, en este caso, predecir si una casa es barata o cara. Con los datos disponibles, existen dos formas de comparar los modelos. Si bien las dos no tienen por qué dar los mismos resultados, son complementarias a la hora de tomar una decisión final.

```{r}
models_cross = data.frame(
"modelo"= c('GLM','knn','Decision_Tree','Random_Forest','SVM'),
 "F_Medida_train" = c(F_reglog_train,F_knn_train,F_dt_train,F_rf_train,F_svm_train))
plot(x = models_cross$modelo, y= models_cross$F_Medida_train,fill=models_cross$modelo)


ggplot(data=models_cross, aes(x=modelo, y=F_Medida_train, fill=modelo)) + 
    geom_bar(stat="identity", position="dodge")

```


# CURVA ROC.

```{r}

# REGRESIÓN LOGÍSTICA
predictions_glm <- predict(model_glm, newdata = datos_train_rl, type = "response")
pred_glm <- prediction(predictions_glm, datos_train_rl$price_categ1)
perf_glm <- performance(pred_glm,"tpr","fpr")

# ARBOL DE DECISION
predictions_tree <- predict(decisiontree_model, newdata = datos_decision_tree, type = "prob")
pred_tree = prediction(predictions_tree[,2], datos_decision_tree$price_categ1)
pref_tree = performance(pred_tree, "tpr", "fpr")

# RANDOM FOREST
predictions_rf <- predict(randomforest_model, new_data=datos_train_limpio, type = "prob")
pred_rf <- prediction(predictions_rf[,2],datos_train_limpio$price_categ1)
perf_rf <- performance(pred_rf,"tpr","fpr")

# SVM
predictions_svm <- predict(modelo_svm, newdata=datos_train_limpio, probability = TRUE)
prob_svm<-attr(predictions_svm,"probabilities")
pred_svm <- prediction(prob_svm[,2], datos_train_limpio$price_categ)
perf_svm <- performance(pred_svm,"tpr","fpr")


plot(perf_glm,col="blue")
plot(pref_tree, col="red",add = TRUE)
plot(perf_rf,col="green", add = TRUE)
plot(perf_svm, col="yellow",add = TRUE)
legend(x="right" ,legend=c("GLM","DT","RF","SVM"),
fill=c("blue","red","green","yellow"),cex=0.8)

```

```{r}

```

# Ideas

cambiar el modelo para que aumente 1000 más la variable respuesta

## para estructurarlo

Primero transformaciones de train, test validacion
Luego cada modelo por separado con su train y test y validacion

## objetivo

## concluisones

* nos quedamos con la acuracy ya que es la única medida que tiene en cuenta los aciertos de las casas caras y de las baratas (la F_medida no tiene en cuenta los TN y la sensibilidad y especificidad solo tienen en cuenta que acierte las caras o las baratas pero no que acierte en ambas)
