---
title: "Machine learning"
author: "Natalia Alonso, Beatriz Martín y Susana Albarrán"
date: "7/2/2020"
output:
  html_document:
    code_folding: show
    number_sections: yes
    fig_height: 5
    fig_width: 8
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
fig_caption: yes
---


```{r, lectura_datos, include=FALSE}
datos <- read.csv("kc_house_data.csv")
```


```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lattice)
library(dplyr)
library(VIM)
library(mice)
library(DMwR2)
library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)
library(GGally)
library(ggplot2)
library(corrplot)
library(vcd)
library(DT)
library(gridExtra)
library(jpeg)
library(car)
library(leaflet)
library(scales)
library(cowplot)
library(useful)
library(rpart)
library(rattle)
library(class)
library(cluster)
library(rpart)
library(rpart.plot)
library(rattle)
library(caret)
library(randomForest)
library(e1071)

```


# Introducción

Los datos que se van a analizar en este proyecto han sido obtenidos desde Kaggle. Contienen precios de casas que fueron vendidas desde mayo de 2014 hasta mayo de 2015 en **King County** que es un condado ubicado en el estado estadounidense de Washington. 

# Objetivo del estudio

Lo que queremos hacer con estos datos es predecir el precio de las casas dependiendo de los datos recogidos.


# Datos

## Categorización del precio

En nuestro estudio inicial, la variable **"Precio"** es continua, por lo que vamos a categorizarla. Se van a realizar dos tipos de cetegorizaciones:

-  **Categorización_1**: se ha categorizado en dos grupos, **B1**, casas baratas (casas con un precio inferior a 500.000) y casas caras, ***C1** (precio> 500.000)
- **Categorización2**: se ha categorizado en tres grupos, **B2**, casas baratas (casas con un precio < 330.000), casas precio medio, **M2** (330.000<precio< 650.000) y casas caras, ***C2** (precio> 650.000

Para decidir las categorizaciones se ha optado por los cuantiles.

```{r}
#Categorizamos la variable respuesta price:
quantile(datos$price, prob=seq(0, 1, length = 5))
datos$price_categ1 <- cut(datos$price, breaks = c(0, 500000, 100000000), labels = c("B1", "C1"))
table(datos$price_categ1)

datos$price_categ2 <- cut(datos$price, breaks = c(0, 330000, 650000, 100000000), labels = c("B2","M2", "C2"))
table(datos$price_categ2)

```

A continuación se muestran cómo están categorizados los datos:

```{r, fig.align='center', warning=FALSE}

#Categorizamos la variable respuesta price: histogramas

tabla_categ1<-table(datos$price_categ1)
barplot(tabla_categ1, main= "Categorización_1 del precio", xlab="precio_categ1",ylab="Nº de casas", col = c("green", "red"))


tabla_categ2<-table(datos$price_categ2)
barplot(tabla_categ2,main="Categorización_2 del precio", xlab="precio_categ2",ylab="Nº de casas", col = c("green", "red", "purple")) 



```

## Train, test y validación

Se va a separar los datos en los 3 conjuntos de datos fundamentales:  

-  Conjunto de datos de **entrenamiento**: en nuestro estudio **datos_train**, se corresponde con el 70% del total de los datos.
-  Conjunto de datos de **validación**: en nuestro estudio **datos_validacion**, se corresponde con el 15% del total de los datos.
-  Conjunto de datos de **test**: en nuestro estudia **datos_test**, se corresponde con el 15% del total de los datos.


```{r, fig.align='center', warning=FALSE}

num_total=nrow(datos)
set.seed(122556) #reproductividad

# 70% para train
indices_train = sample(1:num_total, .7*num_total)
datos_train = datos[indices_train,]

# 15% para test
indices=seq(1:num_total)
indices_test=indices[-indices_train]
indices_test1 = sample(indices_test, .15*num_total)
datos_test = datos[indices_test1,]

# 15% para validacion
indices_validacion=indices[c(-indices_train,-indices_test1)]
datos_validacion=datos[indices_validacion,]

```


## Análisis exploratorio

Se van a realizar transformaciones de un conjunto de variables, estas transformaciones se aplicarán a cada conjunto de datos, train, test y validación:

  - Se realiza una transformación logarítmica sobre las variables sqft_living (pies cuadrados de la casa),   sqft_lot (pies cuadrados del jardín) y sqft_above (pies cuadrados poe encima del suelo), hay que aclarar que esta última variable esla diferencia entre sqft_living y sqft_basement por lo que va a estar altamentente correlad con sqft_living.

  - Se categorizan las variables:
  
    + Bathroom, esta varible puede tomar valores decimales de 0.25 en 0.25. El número de baños se contabiliza por las piezas y cada baño completo tiene 4 piezas, por lo que con la nueva agrupación toma valores de 1 a 8 baños.
  
    + sqft_basement, se categoriza como 0 las casas que no tienen sótano y 1 las casas que sí tienen sótano. 
  
    + grade, se va a categorizar del siguiente modo con valor 0=calidad Baja, 1= calidad media y 2= calidad alta.

    + year_renovated,  se categoriza como  0 = no ha tenido renovación y 1 = sí ha tenido renovación.
 
  - Se pasan a factor las variables: waterfront, view, condition, grade_categ y zipcode
  
  - Se eliminan Outliers.


### Transformaciones datos Train

```{r, fig.align='center', warning=FALSE}
datos_train <- datos_train[,-2]

datos_train$id <- as.factor(datos_train$id)

datos_train$bathrooms_group <- cut(datos_train$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_train$bathrooms_group <- as.numeric(as.character(datos_train$bathrooms_group))

datos_train$log_sqft_living <- log10(datos_train$sqft_living)
datos_train$log_lot <- log10(datos_train$sqft_lot)
datos_train$log_above <- log10(datos_train$sqft_above)

datos_train$sqft_basement_cat <- cut(datos_train$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_train$waterfront<-as.factor(datos_train$waterfront)

datos_train$view<-as.factor(datos_train$view)

datos_train$condition<-as.factor(datos_train$condition)

datos_train$grade_categ <- cut(datos_train$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_train$yr_renovated_catg <-cut(datos_train$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_train$zipcode<-as.factor(datos_train$zipcode)

```

#### Eliminación de Outliers

```{r, fig.align='center', warning=FALSE}
datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_habitaciones<-datos_train[datos_train$bedrooms==0,]$posicion
datos_train<-datos_train[-indices_cero_habitaciones,]

datos_train$posicion<-c(1:nrow(datos_train))
indices_cero_banos<-datos_train$posicion[datos_train$bathrooms_group==0]
datos_train<-datos_train[-indices_cero_banos,]

datos_train$posicion<-c(1:nrow(datos_train))
indice_hab33 <- datos_train[datos_train$bedrooms==33,]$posicion
datos_train[datos_train$posicion == indice_hab33,]$bedrooms = 3
```


### Transformaciones adicionales:

Se han realizado dos categorizaciones adicionales sobre el conjunto de datos. En este caso para ver cómo clasificaban estas variables se ha usado un arbol de decisión, las variables son:  **zipcode** y para **bathrooms_group**

- **Zipcode**, esta variable es de tipo factor y tenía 70 códigos postales, por lo que se ha decidido aplicar un arbol de decisión para ver cómo clasificaba los códigos postales y así volver a categorizarla según el resultado obtenido.

```{r}

model_selec_zipcode<-rpart(price_categ1~zipcode,data=datos_train ,parms=list(split="gini"))

print(model_selec_zipcode)
```

Se va a categorizar en dos zona1 y Zona2.

```{r}


datos_train$zona<-recode(datos_train$zipcode, "98001=1; 98002=1; 98003=1; 98010=1; 98011=1; 98014=1; 98019=1; 98022=1; 98023=1; 98024=1; 98028=1; 98030=1; 98031=1; 98032=1; 98034=1; 98038=1; 98042=1; 98045=1; 98055=1; 98056=1; 98058=1; 98059=1; 98070=1; 98092=1 ;98106=1; 98108=1; 98118=1; 98125=1; 98126=1; 98133=1; 98144=1; 98146=1; 98148=1; 98155=1; 98166=1; 98168=1; 98178=1; 98188=1; 98198=1; 98004=2; 98005=2; 98006=2; 98007=2; 98008=2; 98027=2; 98029=2; 98033=2; 98039=2; 98040=2; 98052=2; 98053=2; 98065=2; 98072=2; 98074=2; 98075=2; 98077=2; 98102=2; 98103=2; 98105=2; 98107=2; 98109=2; 98112=2; 98115=2; 98116=2; 98117=2; 98119=2; 98122=2; 98136=2; 98177=2; 98199=2")

datos_train$zipcode = NULL

```

- **bathrooms_group**, se aplica el mismo método que con zipcode para ver cómo se puede categorizar esta variable. Toma valores de 1 a 8 y queremos reducir el número de níveles.


```{r}


model_selec_bathrooms<-rpart(price_categ1~bathrooms_group,data=datos_train ,parms=list(split="gini"))

print(model_selec_bathrooms)

```

En el resultado del modelo se ve que corta en el número de baños <2.5, por lo que se va a categorizar como 0 aquellas casas que tengan de 1 a 2 baños y como 1 las casas que tengan más de 2 baños.

```{r}

datos_train$bathrooms_group <- cut(datos_train$bathrooms_group, breaks = c(-1,2.5,8),labels=c(0,1))
#0 1ó 2 baños, 1 de 3 baños en adelante

```


```{r}

datos_train_limpio <- datos_train[c(3,22:26,8:10,27,16,17,30,15,20,21)]

#Eliminamos sqft_above porque es una combinalción lineal de sqft_living, están altamente correladas........

datos_train_limpio$log_above = NULL


datos_train_numeric <- datos_train_limpio %>% select_if(is.numeric)
```



### Transformaciones datos Test

Realizamos todas las transformaciones y categorizaciones para el conjunto de datos de test.

```{r, fig.align='center', warning=FALSE}

datos_test <- datos_test[,-2]

datos_test$id <- as.factor(datos_test$id)

datos_test$bathrooms_group <- cut(datos_test$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_test$bathrooms_group <- as.numeric(as.character(datos_test$bathrooms_group))

datos_test$log_sqft_living <- log10(datos_test$sqft_living)
datos_test$log_lot <- log10(datos_test$sqft_lot)
datos_test$log_above <- log10(datos_test$sqft_above)

datos_test$sqft_basement_cat <- cut(datos_test$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_test$waterfront<-as.factor(datos_test$waterfront)

datos_test$view<-as.factor(datos_test$view)

datos_test$condition<-as.factor(datos_test$condition)

datos_test$grade_categ <- cut(datos_test$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_test$yr_renovated_catg <-cut(datos_test$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_test$zipcode<-as.factor(datos_test$zipcode)

#codificar la variable Zipcode

datos_test$zona<-recode(datos_test$zipcode, " 98001=1; 98002=1; 98003=1; 98010=1; 98011=1; 98014=1; 98019=1; 98022=1; 98023=1; 98024=1; 98028=1; 98030=1; 98031=1; 98032=1; 98034=1; 98038=1; 98042=1; 98045=1; 98055=1; 98056=1; 98058=1; 98059=1; 98070=1; 98092=1 ;98106=1; 98108=1; 98118=1; 98125=1; 98126=1; 98133=1; 98144=1; 98146=1; 98148=1; 98155=1; 98166=1; 98168=1; 98178=1; 98188=1; 98198=1; 98004=2; 98005=2; 98006=2; 98007=2; 98008=2; 98027=2; 98029=2; 98033=2; 98039=2; 98040=2; 98052=2; 98053=2; 98065=2; 98072=2; 98074=2; 98075=2; 98077=2; 98102=2; 98103=2; 98105=2; 98107=2; 98109=2; 98112=2; 98115=2; 98116=2; 98117=2; 98119=2; 98122=2; 98136=2; 98177=2; 98199=2")

datos_test$zipcode = NULL

datos_test$bathrooms_group <- cut(datos_test$bathrooms_group, breaks = c(-1,2.5,8),labels=c(0,1))

#0 1ó 2 baños, 1 de 3 baños en adelante
```



```{r}
datos_test_limpio <- datos_test[c(3,22:26,8:10,27,16,17,29,15,20,21)]
datos_test_limpio$log_above = NULL
datos_test_numeric <- datos_test_limpio %>% select_if(is.numeric)
```

## Transformaciones datos Validación

Realizamos todas las transformaciones y categorizaciones para el conjunto de datos de Validación.

```{r, fig.align='center', warning=FALSE}

datos_validacion <- datos_validacion[,-2]

datos_validacion$id <- as.factor(datos_validacion$id)

datos_validacion$bathrooms_group <- cut(datos_validacion$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))
datos_validacion$bathrooms_group <- as.numeric(as.character(datos_validacion$bathrooms_group))

datos_validacion$log_sqft_living <- log10(datos_validacion$sqft_living)
datos_validacion$log_lot <- log10(datos_validacion$sqft_lot)
datos_validacion$log_above <- log10(datos_validacion$sqft_above)

datos_validacion$sqft_basement_cat <- cut(datos_validacion$sqft_basement,breaks = c(-1,0,6000),labels=c(0,1))

datos_validacion$waterfront<-as.factor(datos_validacion$waterfront)

datos_validacion$view<-as.factor(datos_validacion$view)

datos_validacion$condition<-as.factor(datos_validacion$condition)

datos_validacion$grade_categ <- cut(datos_validacion$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

datos_validacion$yr_renovated_catg <-cut(datos_validacion$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

datos_validacion$zipcode<-as.factor(datos_validacion$zipcode)

#codificar la variable Zipcode

datos_validacion$zona<-recode(datos_validacion$zipcode, " 98001=1; 98002=1; 98003=1; 98010=1; 98011=1; 98014=1; 98019=1; 98022=1; 98023=1; 98024=1; 98028=1; 98030=1; 98031=1; 98032=1; 98034=1; 98038=1; 98042=1; 98045=1; 98055=1; 98056=1; 98058=1; 98059=1; 98070=1; 98092=1 ;98106=1; 98108=1; 98118=1; 98125=1; 98126=1; 98133=1; 98144=1; 98146=1; 98148=1; 98155=1; 98166=1; 98168=1; 98178=1; 98188=1; 98198=1; 98004=2; 98005=2; 98006=2; 98007=2; 98008=2; 98027=2; 98029=2; 98033=2; 98039=2; 98040=2; 98052=2; 98053=2; 98065=2; 98072=2; 98074=2; 98075=2; 98077=2; 98102=2; 98103=2; 98105=2; 98107=2; 98109=2; 98112=2; 98115=2; 98116=2; 98117=2; 98119=2; 98122=2; 98136=2; 98177=2; 98199=2")

datos_validacion$zipcode = NULL

datos_validacion$bathrooms_group <- cut(datos_validacion$bathrooms_group, breaks = c(-1,2.5,8),labels=c(0,1))

```

```{r}
datos_validacion_limpio <- datos_validacion[c(3,22:26,8:10,27,16,17,29,15,20,21)]
datos_validacion_limpio$log_above = NULL

datos_validacion_numeric <- datos_validacion_limpio %>% select_if(is.numeric)
```


En este mapa se puede visualizar cómo se distribuyen las casas **"Caras"** y **"Baratas"**. Se observa que las casas que están cercanas al agua y a cerca de Seattle por la parte Norte, son más caras y hacia el sur más baratas.

```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red"), 
                       datos_train_limpio$price_categ1 )

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(datos_train_limpio$price_categ1))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~datos_train_limpio$price_categ1,
            title = "Tipos de Casas",
            opacity = 1)

```


```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red","yellow"), 
                       datos_train_limpio$price_categ2 )

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(datos_train_limpio$price_categ2))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~datos_train_limpio$price_categ2,
            title = "Tipos de Casas",
            opacity = 1)

```

```{r}
#Aquí nos cargamos ya price_categ2

datos_train_limpio$price_categ2= NULL
datos_test_limpio$price_categ2= NULL
datos_validacion_limpio$price_categ2 = NULL

```



# Métodos de agrupamiento-No supervisado

## K-Means

### Train

Primero se van a realizar los gráficos para ver cómo están diferenciadas las casa por precio. Para poder visualizarlo en dos dimensiones se ha usado la función **"prcomp"** (PCA)

```{r}
colores1= c("red","blue")
colores11 = colores1[datos_train_limpio$price_categ1]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n",main= "Dos categorías")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(datos_train_limpio$price_categ1), col=colores11)

```

A continuación se va a aplicar el método de agrupamiento de K-means. se van a escalar los datos.

```{r}
datos_scale<- as.data.frame(scale(datos_train_numeric))
set.seed(1234)
modelkm1 <- kmeans(datos_scale, centers=2)

#table(modelkm2$cluster) #asignación de observación a los cluster
# modelkm1$totss  #Inercia total
# modelkm1$betweenss  #Inercia inter grupos
# modelkm1$withinss   #Inercia intra grupos
# modelkm1$tot.withinss  #inercia total intra grupos

```



```{r}
colores1= c("red","blue")
colores11 = colores1[datos_train_limpio$price_categ1]

plot(prcomp(datos_train_numeric, scale = T)$x[,1:2], type="n")
text(prcomp(datos_train_numeric, scale = T)$x[,1:2], as.character(modelkm1$cluster), col=colores11)

```


```{r}

clusterkmeans=as.data.frame(modelkm1$cluster)

clusterkmeans$indice= as.integer(rownames(clusterkmeans))

colnames(clusterkmeans)[1]= "categoria_price_km"
clustering1= clusterkmeans[order(clusterkmeans$indice),]
```


Se visualiza como se reparten las casas según el agrupamiento que se ha realizado con K-Means:

```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal1 <- colorFactor(c("green","red"), 
                       clustering1$categoria_price_km )

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal1(clustering1$categoria_price_km))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal1 , values = ~clustering1$categoria_price_km,
            title = "Tipos de casas",
            opacity = 1)

```

Cómo se observa en el mapa, y si lo comparamos con el de los datos iniciales, dista bastante. Por lo que deducimos que la agrupación que está relalizando K-Means no es muy buena.

#### Evaluación del modelo

```{r}
tabla2=table(datos_train_limpio$price_categ1,modelkm1$cluster)
#caras
pred.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[1,2])
rec.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
#baratas
pred.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[2,1])
rec.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
accuracy = (tabla2[1,1]+tabla2[2,2]) / (tabla2[1,1]+tabla2[1,2]+tabla2[2,1]+tabla2[2,2])
accuracy
```


#### Test

#### Validación

## K-Medoids 



```{r}

datoskmedoids = datos_train_limpio[,-15]

wbPam = pam(x = datoskmedoids, k = 2, keep.diss = TRUE,
keep.data = TRUE)

wbPam$medoids


plot(wbPam, main = "silhouette plot")
```

```{r}
#wbPam$clustering
#clustering= sort(wbPam$clustering)

clustering=as.data.frame(wbPam$clustering)

clustering$indice= as.integer(rownames(clustering))

colnames(clustering)[1]= "categoria_price"
clustering2= clustering[order(clustering$indice),]

```


```{r, fig.align='center', warning=FALSE}

center_lon = median(datoskmedoids$long,na.rm = TRUE)
center_lat = median(datoskmedoids$lat,na.rm = TRUE)

factpal2 <- colorFactor(c("green","red"), 
                       clustering2$categoria_price )

leaflet(datoskmedoids) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal2(clustering2$categoria_price))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal2 , values = ~clustering2$categoria_price,
            title = "Tipos de casas",
            opacity = 1)

```


# Técnicas de reducción de la dimensionalidad:

## PCA

Es un método que permite simplificar la complejidad de espacios muestrales con muchas dimensiones a la vez que conserva su información.

```{r}

pca<-prcomp(datos_train_numeric,scale=T)
plot(prcomp(datos_train_numeric,scale=T))

#pca$center para saber la media de cada variable
#pca$scale para saber la desv.típica de cada variable

```

```{r}
summary(prcomp(datos_train_numeric, scale=T))

biplot(x = pca, scale = 0, cex = 0.6, col = c("blue4", "brown3"))
```

# Aprendizaje supervisado 

## GLM-Regresión Logística.

Con este modelo se va a estudiar si existe relación entre el hecho de que una casa sea "cara" ó "barata" dependiendo de las características de las casas.Se va a generar un modelo en el que a apartir de las variables,.....prediga la probabilidad de que una casa sea barata o cara.


### Train

```{r}
datos_train_rl <- datos_train_limpio[,-c(8,9)]
datos_train_rl$price_categ1<- recode(datos_train_rl$price_categ1, "'B1'=0; 'C1'=1")


```


```{r}

model_glm = glm(price_categ1 ~., family = binomial,
data =datos_train_rl )
summary(model_glm)

```
```{r}

predicciones <- ifelse(test = model_glm$fitted.values > 0.5, yes = 1, no = 0)
tabla2 <- table(model_glm$model$price_categ1, predicciones,
                          dnn = c("observaciones", "predicciones"))
tabla2

#caras

pred.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[1,2])
rec.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2

```

```{r}
#baratas
pred.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[2,1])
rec.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
accuracy = (tabla2[1,1]+tabla2[2,2]) / (tabla2[1,1]+tabla2[1,2]+tabla2[2,1]+tabla2[2,2])
accuracy
```


Explicamos con palabras porqué este modelo no es bueno. En vez de seguir con test y validación se descartan.


```{r}

#ggplot(subset(datos_train_rl, select = c(bedrooms,bathrooms_group, #log_sqft_living, log_lot, log_above, lat, long, price_categ1)), aes(x = #bathrooms_group,
#y = price_categ1)) + geom_point() +  # geom_smooth(method = 'glm', method.args = list(family =
# 'binomial'), se=FALSE) +
#geom_line(data = data.frame(bathrooms_group = data.frame(bathrooms_group = #seq(1,8,1)), price_categ1 = predict(model_glm, data.frame(bathrooms_group = #seq(1,8,1)), type = "response")), colour = "navy")


```



## KNN


Ver con cuantos vecinos:

```{r}

suppressWarnings(suppressMessages(library(kknn)))
modelo <- train.kknn(price_categ1 ~ ., data = datos_train_limpio, kmax = 10)
modelo

```


### Train

```{r}
#k=1
#train
constante = 1
knn.train1=knn.cv(scale(datos_train_numeric),cl=as.factor(datos_train_limpio$price_categ1),k=constante)
tabla.knn.train1=table(knn.train1,datos_train_limpio$price_categ1)
pred.knn.train1=tabla.knn.train1[2,2]/(tabla.knn.train1[2,2]+tabla.knn.train1[1,2])
rec.knn.train1=tabla.knn.train1[2,2]/(tabla.knn.train1[2,2]+tabla.knn.train1[2,1])
F_medida.knn.train1=(5*pred.knn.train1*rec.knn.train1)/(4*pred.knn.train1+rec.knn.train1)
F_medida.knn.train1
tabla.knn.train1
```

```{r}
#k=2
#train
knn.train2=knn.cv(scale(datos_train_numeric),cl=as.factor(datos_train_limpio$price_categ1),k=2)
tabla.knn.train2=table(knn.train2,datos_train_limpio$price_categ1)
pred.knn.train2=tabla.knn.train2[2,2]/(tabla.knn.train2[2,2]+tabla.knn.train2[1,2])
rec.knn.train2=tabla.knn.train2[2,2]/(tabla.knn.train2[2,2]+tabla.knn.train2[2,1])
F_medida.knn.train2=(5*pred.knn.train2*rec.knn.train2)/(4*pred.knn.train2+rec.knn.train2)
F_medida.knn.train2
tabla.knn.train2

```


```{r, fig.align='center', warning=FALSE}

center_lon = median(datos_train_limpio$long,na.rm = TRUE)
center_lat = median(datos_train_limpio$lat,na.rm = TRUE)

factpal1 <- colorFactor(c("green","red"), 
                       knn.train2)

leaflet(datos_train_limpio) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal1(knn.train2))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal1 , values = ~knn.train2,
            title = "Precio (en miles de $)",
            opacity = 1)

```

```{r}

tabla2=table(datos_train_limpio$price_categ1,knn.train2)

#caras
pred.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[1,2])
rec.means2=tabla2[2,2]/(tabla2[2,2]+tabla2[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2

```

```{r}
#baratas
pred.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[2,1])
rec.means2=tabla2[1,1]/(tabla2[1,1]+tabla2[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2
```

```{r}
accuracy = (tabla2[1,1]+tabla2[2,2]) / (tabla2[1,1]+tabla2[1,2]+tabla2[2,1]+tabla2[2,2])
accuracy
```



### Test

```{r}

knn.test2=knn(scale(datos_train_numeric),scale(datos_test_numeric),cl=datos_train_limpio$price_categ1,k=2)

tabla2_test=table(datos_test_limpio$price_categ1,knn.test2)
#caras
pred.means2=tabla2_test[2,2]/(tabla2_test[2,2]+tabla2_test[1,2])
rec.means2=tabla2_test[2,2]/(tabla2_test[2,2]+tabla2_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_test


```

```{r}
#baratas
pred.means2=tabla2_test[1,1]/(tabla2_test[1,1]+tabla2_test[2,1])
rec.means2=tabla2_test[1,1]/(tabla2_test[1,1]+tabla2_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_test
```

```{r}
accuracy = (tabla2_test[1,1]+tabla2_test[2,2]) / (tabla2_test[1,1]+tabla2_test[1,2]+tabla2_test[2,1]+tabla2_test[2,2])
accuracy
```


### Validación

```{r}

knn.val=knn(scale(datos_train_numeric),scale(datos_validacion_numeric),cl=datos_train_limpio$price_categ1,k=2)

tabla2_val=table(datos_validacion_limpio$price_categ1,knn.val)
#caras
pred.means2=tabla2_val[2,2]/(tabla2_val[2,2]+tabla2_val[1,2])
rec.means2=tabla2_val[2,2]/(tabla2_val[2,2]+tabla2_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_val
```

```{r}
#baratas
pred.means2=tabla2_val[1,1]/(tabla2_val[1,1]+tabla2_val[2,1])
rec.means2=tabla2_val[1,1]/(tabla2_val[1,1]+tabla2_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla2_val
```

```{r}
accuracy = (tabla2_val[1,1]+tabla2_val[2,2]) / (tabla2_val[1,1]+tabla2_val[1,2]+tabla2_val[2,1]+tabla2_val[2,2])
accuracy
```

## Decision Trees

### Train


```{r}

#quitamos lat y long:
datos_decision_tree<-datos_train_limpio[,-c(11,12)]

decisiontree_model=rpart(price_categ1~bathrooms_group, data=datos_decision_tree,parms=list(split="gini") )
#resumen=summary(decisiontree_model)
print(decisiontree_model)

#kk=as.data.frame(summary(decisiontree_model))

fancyRpartPlot(decisiontree_model)
#rpart.plot(decisiontree_model)
#prp(decisiontree_model, type = 2, extra = 6, split.font = 3)

```

```{r}

tabla.train.arbol1=table(obs = datos_decision_tree$price_categ1, pred = predict(decisiontree_model, type = "class"))

tabla.train.arbol1

tabla.train.arbol2=table(obs = datos_train_limpio$price_categ1, pred = predict(decisiontree_model, type = "class") )

tabla.train.arbol2


```

```{r}
#caras
pred.means2=tabla.train.arbol1[2,2]/(tabla.train.arbol1[2,2]+tabla.train.arbol1[1,2])
rec.means2=tabla.train.arbol1[2,2]/(tabla.train.arbol1[2,2]+tabla.train.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.train.arbol1
```

```{r}
#baratas
pred.means2=tabla.train.arbol1[1,1]/(tabla.train.arbol1[1,1]+tabla.train.arbol1[2,1])
rec.means2=tabla.train.arbol1[1,1]/(tabla.train.arbol1[1,1]+tabla.train.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.train.arbol1
```

```{r}
accuracy = (tabla.train.arbol1[1,1]+tabla.train.arbol1[2,2]) / (tabla.train.arbol1[1,1]+tabla.train.arbol1[1,2]+tabla.train.arbol1[2,1]+tabla.train.arbol1[2,2])
accuracy
```

### Test

```{r}


tabla.test.arbol1=table(obs = datos_test_limpio$price_categ1, pred = predict(decisiontree_model,datos_test_limpio[,-15], type ="class"))

tabla.test.arbol1
#caras
pred.means2=tabla.test.arbol1[2,2]/(tabla.test.arbol1[2,2]+tabla.test.arbol1[1,2])
rec.means2=tabla.test.arbol1[2,2]/(tabla.test.arbol1[2,2]+tabla.test.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.test.arbol1


```

```{r}
#baratas
pred.means2=tabla.test.arbol1[1,1]/(tabla.test.arbol1[1,1]+tabla.test.arbol1[2,1])
rec.means2=tabla.test.arbol1[1,1]/(tabla.test.arbol1[1,1]+tabla.test.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.test.arbol1
```

```{r}
accuracy = (tabla.test.arbol1[1,1]+tabla.test.arbol1[2,2]) / (tabla.test.arbol1[1,1]+tabla.test.arbol1[1,2]+tabla.test.arbol1[2,1]+tabla.test.arbol1[2,2])
accuracy
```


### Validacion

```{r}


tabla.validacion.arbol1=table(obs = datos_validacion_limpio$price_categ1, pred = predict(decisiontree_model,datos_validacion_limpio[,-15], type ="class"))

tabla.validacion.arbol1
#caras
pred.means2=tabla.validacion.arbol1[2,2]/(tabla.validacion.arbol1[2,2]+tabla.validacion.arbol1[1,2])
rec.means2=tabla.validacion.arbol1[2,2]/(tabla.validacion.arbol1[2,2]+tabla.validacion.arbol1[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.validacion.arbol1


```

```{r}
#baratas
pred.means2=tabla.validacion.arbol1[1,1]/(tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[2,1])
rec.means2=tabla.validacion.arbol1[1,1]/(tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla.validacion.arbol1
```

```{r}
accuracy = (tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[2,2]) / (tabla.validacion.arbol1[1,1]+tabla.validacion.arbol1[1,2]+tabla.validacion.arbol1[2,1]+tabla.validacion.arbol1[2,2])
accuracy
```

## Random Forest

### Train

```{r}
randomforest_model=randomForest(price_categ1~., data=datos_train_limpio,parms=list(split="gini") )
resumen=summary(decisiontree_model)
resumen
#print(randomforest_model)


#kk=as.data.frame(summary(decisiontree_model))

#fancyRpartPlot(decisiontree_model)
#rpart.plot(decisiontree_model)
#prp(decisiontree_model, type = 2, extra = 6, split.font = 3)

```

```{r}

tabla_randomforest=table(obs = datos_train_limpio$price_categ1, pred = predict(randomforest_model, type = "class") )

tabla_randomforest

```

```{r}
#caras
pred.means2=tabla_randomforest[2,2]/(tabla_randomforest[2,2]+tabla_randomforest[1,2])
rec.means2=tabla_randomforest[2,2]/(tabla_randomforest[2,2]+tabla_randomforest[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest
```

```{r}
#baratas
pred.means2=tabla_randomforest[1,1]/(tabla_randomforest[1,1]+tabla_randomforest[2,1])
rec.means2=tabla_randomforest[1,1]/(tabla_randomforest[1,1]+tabla_randomforest[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest
```

```{r}
accuracy = (tabla_randomforest[1,1]+tabla_randomforest[2,2]) / (tabla_randomforest[1,1]+tabla_randomforest[1,2]+tabla_randomforest[2,1]+tabla_randomforest[2,2])
accuracy
```

### Test

```{r}

tabla_randomforest_test=table(obs = datos_test_limpio$price_categ1, pred = predict(randomforest_model,datos_test_limpio[,-15], type ="class"))
tabla_randomforest_test

#caras
pred.means2=tabla_randomforest_test[2,2]/(tabla_randomforest_test[2,2]+tabla_randomforest_test[1,2])
rec.means2=tabla_randomforest_test[2,2]/(tabla_randomforest_test[2,2]+tabla_randomforest_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_test


```

```{r}
#baratas
pred.means2=tabla_randomforest_test[1,1]/(tabla_randomforest_test[1,1]+tabla_randomforest_test[2,1])
rec.means2=tabla_randomforest_test[1,1]/(tabla_randomforest_test[1,1]+tabla_randomforest_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_test
```

```{r}
accuracy = (tabla_randomforest_test[1,1]+tabla_randomforest_test[2,2]) / (tabla_randomforest_test[1,1]+tabla_randomforest_test[1,2]+tabla_randomforest_test[2,1]+tabla_randomforest_test[2,2])
accuracy
```

### Validacion

```{r}


tabla_randomforest_val=table(obs = datos_validacion_limpio$price_categ1, pred = predict(randomforest_model,datos_validacion_limpio[,-15], type ="class"))

tabla_randomforest_val
#caras
pred.means2=tabla_randomforest_val[2,2]/(tabla_randomforest_val[2,2]+tabla_randomforest_val[1,2])
rec.means2=tabla_randomforest_val[2,2]/(tabla_randomforest_val[2,2]+tabla_randomforest_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_val


```

```{r}
#baratas
pred.means2=tabla_randomforest_val[1,1]/(tabla_randomforest_val[1,1]+tabla_randomforest_val[2,1])
rec.means2=tabla_randomforest_val[1,1]/(tabla_randomforest_val[1,1]+tabla_randomforest_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_randomforest_val
```

```{r}
accuracy = (tabla_randomforest_val[1,1]+tabla_randomforest_val[2,2]) / (tabla_randomforest_val[1,1]+tabla_randomforest_val[1,2]+tabla_randomforest_val[2,1]+tabla_randomforest_val[2,2])
accuracy
```

## SVM

```{r}
modelo_svm <- svm(formula = price_categ1 ~., data = datos_train_limpio, kernel = "linear" ,scale = FALSE)
summary(modelo_svm)

#plot(modelo_svm, datos_train_limpio_dt)
```
```{r}
#set.seed(1)
#tune.out = tune(svm,price_categ1 ~ ., data = datos_train_limpio_dt, kernel = "linear", ranges = list(cost = c(0.001,
#0.01, 0.1, 1, 5, 10, 100)))

```

### Train

```{r}

tabla_svm_train=table(obs = datos_train_limpio$price_categ1, pred = predict(modelo_svm,datos_train_limpio[,-15], type ="class"))

tabla_svm_train
#caras
pred.means2=tabla_svm_train[2,2]/(tabla_svm_train[2,2]+tabla_svm_train[1,2])
rec.means2=tabla_svm_train[2,2]/(tabla_svm_train[2,2]+tabla_svm_train[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_train


```

```{r}
#baratas
pred.means2=tabla_svm_train[1,1]/(tabla_svm_train[1,1]+tabla_svm_train[2,1])
rec.means2=tabla_svm_train[1,1]/(tabla_svm_train[1,1]+tabla_svm_train[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_train
```

```{r}
accuracy = (tabla_svm_train[1,1]+tabla_svm_train[2,2]) / (tabla_svm_train[1,1]+tabla_svm_train[1,2]+tabla_svm_train[2,1]+tabla_svm_train[2,2])
accuracy
```

### Test

```{r}

tabla_svm_test=table(obs = datos_test_limpio$price_categ1, pred = predict(modelo_svm,datos_test_limpio[,-15], type ="class"))
tabla_svm_test

#caras
pred.means2=tabla_svm_test[2,2]/(tabla_svm_test[2,2]+tabla_svm_test[1,2])
rec.means2=tabla_svm_test[2,2]/(tabla_svm_test[2,2]+tabla_svm_test[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_test


```

```{r}
#baratas
pred.means2=tabla_svm_test[1,1]/(tabla_svm_test[1,1]+tabla_svm_test[2,1])
rec.means2=tabla_svm_test[1,1]/(tabla_svm_test[1,1]+tabla_svm_test[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_test
```

```{r}
accuracy = (tabla_svm_test[1,1]+tabla_svm_test[2,2]) / (tabla_svm_test[1,1]+tabla_svm_test[1,2]+tabla_svm_test[2,1]+tabla_svm_test[2,2])
accuracy
```

### Validacion

```{r}

tabla_svm_val=table(obs = datos_validacion_limpio$price_categ1, pred = predict(modelo_svm,datos_validacion_limpio[,-15], type ="class"))

tabla_svm_val
#caras
pred.means2=tabla_svm_val[2,2]/(tabla_svm_val[2,2]+tabla_svm_val[1,2])
rec.means2=tabla_svm_val[2,2]/(tabla_svm_val[2,2]+tabla_svm_val[2,1])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_val
```

```{r}
#baratas
pred.means2=tabla_svm_val[1,1]/(tabla_svm_val[1,1]+tabla_svm_val[2,1])
rec.means2=tabla_svm_val[1,1]/(tabla_svm_val[1,1]+tabla_svm_val[1,2])
F_medida.means2=(2*pred.means2*rec.means2)/(pred.means2+rec.means2)
F_medida.means2
tabla_svm_val
```

```{r}
accuracy = (tabla_svm_val[1,1]+tabla_svm_val[2,2]) / (tabla_svm_val[1,1]+tabla_svm_val[1,2]+tabla_svm_val[2,1]+tabla_svm_val[2,2])
accuracy
```



# Ideas

cambiar el modelo para que aumente 1000 más la variable respuesta

## para estructurarlo

Primero transformaciones de train, test validacion
Luego cada modelo por separado con su train y test y validacion

## objetivo

## concluisones

* nos quedamos con la acuracy ya que es la única medida que tiene en cuenta los aciertos de las casas caras y de las baratas (la F_medida no tiene en cuenta los TN y la sensibilidad y especificidad solo tienen en cuenta que acierte las caras o las baratas pero no que acierte en ambas)
